{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EIHf6OGN6Hk"
   },
   "source": [
    "<h1 style=\"text-align: center;\" class=\"list-group-item list-group-item-action active\">Table of Contents</h1>\n",
    "\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#1\" role=\"tab\"\n",
    "            aria-controls=\"settings\">1. Introduction<span class=\"badge badge-primary badge-pill\">1</span></a>\n",
    "    </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2\" role=\"tab\"\n",
    "            aria-controls=\"settings\">2. Data Acquisition<span class=\"badge badge-primary badge-pill\">2</span></a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2.1\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">2.1 Web Scraping <span class=\"badge badge-primary badge-pill\">3</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2.2\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">2.2 About the Data <span\n",
    "                        class=\"badge badge-primary badge-pill\">4</span></a>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2.3\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">2.3 Handling Missing Values <span\n",
    "                        class=\"badge badge-primary badge-pill\">5</span></a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3\" role=\"tab\"\n",
    "            aria-controls=\"settings\">3. Text Cleaning<span class=\"badge badge-primary badge-pill\">6</span></a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3.1\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">3.1 HTML Parsing and Cleanup <span\n",
    "                        class=\"badge badge-primary badge-pill\">7</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3.2\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">3.2 Unicode Normalization<span\n",
    "                        class=\"badge badge-primary badge-pill\">8</span></a>\n",
    "            <ul style=\"list-style-type:none;\">\n",
    "                <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3.2.1\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">3.2.1 The Issue of Equivalence<span\n",
    "                                class=\"badge badge-primary badge-pill\">9</span></a></li>\n",
    "                <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3.2.2\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">3.2.2 Handling Emoji ‚Äòüòçüòç‚Äô & Emoticon ‚Äò :) ‚Äô <span\n",
    "                                class=\"badge badge-primary badge-pill\">10</span></a></li>\n",
    "            </ul>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3.3\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">3.3 Spelling Correction<span\n",
    "                        class=\"badge badge-primary badge-pill\">11</span></a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4\" role=\"tab\"\n",
    "            aria-controls=\"settings\">4. Text Pre-Processing <span class=\"badge badge-primary badge-pill\">12</span></a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.1\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">4.1 Preliminaries <span\n",
    "                        class=\"badge badge-primary badge-pill\">13</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.2\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">4.2 Frequent Steps <span\n",
    "                        class=\"badge badge-primary badge-pill\">14</span></a>\n",
    "                <ul style=\"list-style-type:none;\">\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.2.1\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">4.2.1 Removing Stop Words<span\n",
    "                                class=\"badge badge-primary badge-pill\">15</span></a></li>\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.2.2\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">4.2.2 Stemming<span\n",
    "                                class=\"badge badge-primary badge-pill\">16</span></a></li>\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.2.3\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">4.2.3 Lemmatization<span\n",
    "                                class=\"badge badge-primary badge-pill\">17</span></a></li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.3\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">4.3 Other Pre-Processing Steps <span\n",
    "                        class=\"badge badge-primary badge-pill\">18</span></a>\n",
    "                <ul style=\"list-style-type:none;\">\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.3.1\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">4.3.1 Language Detection<span\n",
    "                                class=\"badge badge-primary badge-pill\">19</span></a></li>\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.3.2\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">4.3.2 Code mixing and transliteration<span\n",
    "                                class=\"badge badge-primary badge-pill\">20</span></a></li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4.4\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">4.4 Data Augmentation <span\n",
    "                        class=\"badge badge-primary badge-pill\">21</span></a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#5\" role=\"tab\"\n",
    "            aria-controls=\"settings\">5. Latent Dirichlet Allocation (LDA) <span\n",
    "                class=\"badge badge-primary badge-pill\">22</span></a> </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6\" role=\"tab\"\n",
    "            aria-controls=\"settings\">6. Model <span class=\"badge badge-primary badge-pill\">23</span></a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.1\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">6.1 Configurations <span\n",
    "                        class=\"badge badge-primary badge-pill\">24</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.2\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">6.2 Dataset Generator<span\n",
    "                        class=\"badge badge-primary badge-pill\">25</span></a>\n",
    "                <ul style=\"list-style-type:none;\">\n",
    "                    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.2.1\" role=\"tab\"\n",
    "                            aria-controls=\"settings\">6.2.1 Creation of the Vocabulary<span\n",
    "                                class=\"badge badge-primary badge-pill\">26</span></a></li>\n",
    "                </ul>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.3\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">6.3 Word Embeddings<span\n",
    "                        class=\"badge badge-primary badge-pill\">27</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.4\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">6.4 Initializing the Model<span\n",
    "                        class=\"badge badge-primary badge-pill\">28</span></a>\n",
    "            </li>\n",
    "            <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#6.5\" role=\"tab\"\n",
    "                    aria-controls=\"settings\">6.5 Training and K-fold Cross Validation<span\n",
    "                        class=\"badge badge-primary badge-pill\">29</span></a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#7\" role=\"tab\"\n",
    "            aria-controls=\"settings\">7. Inference <span class=\"badge badge-primary badge-pill\">30</span></a> </li>\n",
    "    <li><a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#8\" role=\"tab\"\n",
    "            aria-controls=\"settings\">8. References <span class=\"badge badge-primary badge-pill\">31</span></a> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hSGjDGpPN6Ho"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlChvrS7N6Ho"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">1. Introduction</h1><a id = \"1\" ></a>\n",
    "\n",
    "Before we get into the several strategies for aspect-level sentiment analysis, we must first define an **aspect**. Aspects are a set of semantically rich, concept-centric terms that signify specific features or characteristics of the review or comment. For example, If we consider Example shown below Location, and food are all aspects to consider.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "**Aspect-based sentiment analysis (ABSA)** is a text analysis technique that categorizes data by aspect and identifies the sentiment attributed to each one. We will use it to analyze customer feedback for flipkart products by associating specific sentiments with different aspects of a product or service. \n",
    "\n",
    "\n",
    "Aspect Based Sentiment Analysis can be categorized into two types :-\n",
    "\n",
    "- **Supervised ABSA** :- In Supervised approach we provide the seed words which than help supervised model to extract aspects of the sentence. If it identifies the particular aspects for that seed then it tags those sentences with those aspects.\n",
    "\n",
    "- **Unsupervised ABSA** :- As it is obvious providing the seed for each sentence is a difficult task plus let say if our dataset is large (20-100k) than that will become a nightmare. Topic Modeling is the technique which helps extract latent topics from a document, in our case we will extract aspect from a sentence using topic modeling techniques such as latent Dirichlet algorithm (LDA).\n",
    "\n",
    "Aspect Based Sentiment Analysis is a Natural Language Processing (NLP) Based Approach so we will deal it like that and follow the below mentioned pipeline for a NLP task. \n",
    "\n",
    "![](https://miro.medium.com/max/966/1*rJQVqDjbhI3k22lHqa4dFw.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuWYNZYhN6Hp"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">2. Data Acquisition </h1><a id = \"2\" ></a>\n",
    "\n",
    "Data Acquisition Phase of the NLP pipeline deals with how can we get information rich and clean data form some source. In our case we fetch the data from flipkart's web page using web scraping technique. \n",
    "\n",
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 2.1 Web Scraping </h2><a id = \"2.1\" ></a>\n",
    "\n",
    "Let say we want to analyze the flipkart customers reviews on some Mobile Phone well, we can copy and paste the information from flipkart reviews section to our own file. But in our case we need large amount of data for aspect based sentiment analysis task from the website as quickly as possible. In such a situation, copying and pasting will not work! And that‚Äôs when we‚Äôll need to use **Web Scraping**. \n",
    "\n",
    "Web scraping is a method of extracting large amounts of data from websites in an automated manner. The majority of this information is unstructured HTML data that is converted to structured data in a spreadsheet or database before being used in various applications.\n",
    "\n",
    "I Basically used python library BeautifulSoup to fetch the data from web.\n",
    "\n",
    "In this notebook I will not discuss how web scraping works as it's a bit techniq thing but if you are interested to learn the implementation for web scraping you can go through the following blog post.\n",
    "\n",
    "[A Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hET3PWlzN6Hp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2xkIIArN6Hp"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 2.2 About the Data </h2><a id = \"2.2\" ></a>\n",
    "\n",
    "\n",
    "Before Loading the dataset I want to specify few details about data. The data is fetched from flipkart India web page contains 83 tables in which 1 table contains information about rest 82 tables. Those rest 82 tables contains reviews of 82 mobile phones.\n",
    "\n",
    "A table which contains information about mobile phones has following attributes.\n",
    "\n",
    " - product_id    \n",
    " - product_name  \n",
    " - price         \n",
    " - category      \n",
    " - sub_category  \n",
    " - specifications\n",
    " - ratings       \n",
    " - discount      \n",
    " - moreinfo      \n",
    "\n",
    "Tables containing reviews of 82 mobile phones has following attributes.\n",
    "\n",
    " - product_id  \n",
    " - review_id   \n",
    " - title       \n",
    " - review      \n",
    " - likes       \n",
    " - dislikes    \n",
    " - ratings     \n",
    " - reviewer    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bCq57lpFN6Hq"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"/content/flipkart_products.db\")\n",
    "items = pd.read_sql_query(\"SELECT * from items\", con)\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GOAYv2nuN6Hq",
    "outputId": "7d1c433b-d463-4495-8f31-0259b43e9144"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-44b19515-9c3c-4bf2-b876-8202e5512c2e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>specifications</th>\n",
       "      <th>ratings</th>\n",
       "      <th>discount</th>\n",
       "      <th>moreinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>Redmi 9A (SeaBlue, 32 GB)</td>\n",
       "      <td>‚Çπ7,413</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/redmi-9a-seablue-32-gb/p/itmeabd39a0cd669?pid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECMB000002</td>\n",
       "      <td>Redmi 9A (Midnight Black, 32 GB)</td>\n",
       "      <td>‚Çπ7,421</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>/redmi-9a-midnight-black-32-gb/p/itmeabd39a0cd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECMB000003</td>\n",
       "      <td>Redmi 9A (Nature Green, 32 GB)</td>\n",
       "      <td>‚Çπ7,384</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/redmi-9a-nature-green-32-gb/p/itmeabd39a0cd66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECMB000004</td>\n",
       "      <td>Redmi 9 (Carbon Black, 64 GB)</td>\n",
       "      <td>‚Çπ10,745</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>4 GB RAM | 64 GB ROM16.59 cm (6.53 inch) HD+ D...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>None</td>\n",
       "      <td>/redmi-9-carbon-black-64-gb/p/itm4fb151383983b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECMB000005</td>\n",
       "      <td>Redmi 9 (Sky Blue, 64 GB)</td>\n",
       "      <td>‚Çπ10,489</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>4 GB RAM | 64 GB ROM16.59 cm (6.53 inch) HD+ D...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>None</td>\n",
       "      <td>/redmi-9-sky-blue-64-gb/p/itm4fb151383983b?pid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44b19515-9c3c-4bf2-b876-8202e5512c2e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-44b19515-9c3c-4bf2-b876-8202e5512c2e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-44b19515-9c3c-4bf2-b876-8202e5512c2e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   product_id                      product_name    price     category  \\\n",
       "0  ECMB000001         Redmi 9A (SeaBlue, 32 GB)   ‚Çπ7,413  Electronics   \n",
       "1  ECMB000002  Redmi 9A (Midnight Black, 32 GB)   ‚Çπ7,421  Electronics   \n",
       "2  ECMB000003    Redmi 9A (Nature Green, 32 GB)   ‚Çπ7,384  Electronics   \n",
       "3  ECMB000004     Redmi 9 (Carbon Black, 64 GB)  ‚Çπ10,745  Electronics   \n",
       "4  ECMB000005         Redmi 9 (Sky Blue, 64 GB)  ‚Çπ10,489  Electronics   \n",
       "\n",
       "  sub_category                                     specifications ratings  \\\n",
       "0       Mobile  2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...     4.3   \n",
       "1       Mobile  2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...     4.3   \n",
       "2       Mobile  2 GB RAM | 32 GB ROM16.59 cm (6.53 inch) Full ...     4.3   \n",
       "3       Mobile  4 GB RAM | 64 GB ROM16.59 cm (6.53 inch) HD+ D...     4.2   \n",
       "4       Mobile  4 GB RAM | 64 GB ROM16.59 cm (6.53 inch) HD+ D...     4.2   \n",
       "\n",
       "  discount                                           moreinfo  \n",
       "0      3.0  /redmi-9a-seablue-32-gb/p/itmeabd39a0cd669?pid...  \n",
       "1      3.0  /redmi-9a-midnight-black-32-gb/p/itmeabd39a0cd...  \n",
       "2      4.0  /redmi-9a-nature-green-32-gb/p/itmeabd39a0cd66...  \n",
       "3     None  /redmi-9-carbon-black-64-gb/p/itm4fb151383983b...  \n",
       "4     None  /redmi-9-sky-blue-64-gb/p/itm4fb151383983b?pid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OOcrbrjN6Hq",
    "outputId": "e0de8233-fc87-4d08-dd5d-32db858af56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   product_id      82 non-null     object\n",
      " 1   product_name    82 non-null     object\n",
      " 2   price           82 non-null     object\n",
      " 3   category        82 non-null     object\n",
      " 4   sub_category    82 non-null     object\n",
      " 5   specifications  82 non-null     object\n",
      " 6   ratings         82 non-null     object\n",
      " 7   discount        34 non-null     object\n",
      " 8   moreinfo        82 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlx2KG-xN6Hr"
   },
   "source": [
    "Items dataset is just like an index for some book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G7HpQH3lN6Hr"
   },
   "outputs": [],
   "source": [
    "\n",
    "con = sqlite3.connect(\"/content/flipkart_products.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * from ECMB000001\", con)\n",
    "\n",
    "for i in range(2, len(items) + 1):\n",
    "\n",
    "    df_temp = pd.read_sql_query(\"SELECT * from ECMB{:06d}\".format(i), con)\n",
    "    df = pd.concat([df, df_temp])\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h35grGuNN6Hr",
    "outputId": "3b780713-2896-49e2-b74b-9c41f88ad844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53493 entries, 0 to 289\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   product_id  53493 non-null  object\n",
      " 1   review_id   53493 non-null  object\n",
      " 2   title       53493 non-null  object\n",
      " 3   review      53493 non-null  object\n",
      " 4   likes       53493 non-null  object\n",
      " 5   dislikes    53493 non-null  object\n",
      " 6   ratings     48488 non-null  object\n",
      " 7   reviewer    53493 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hzZG9jUuN6Hr",
    "outputId": "0994c8af-7f44-4657-ef3a-eafb59126c23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e6e89ba9-7ab7-405f-b83b-5759be9b3de5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviewer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>ECMB0000010000001</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Wow superb I love it‚ù§Ô∏èüëç battery backup so nice üëçüëç</td>\n",
       "      <td>740</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>Abhishek Saini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>ECMB0000010000002</td>\n",
       "      <td>Worth the money</td>\n",
       "      <td>Mobile So Good In Range Redmi 9a Has Miui 12 L...</td>\n",
       "      <td>355</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>Dinesh Kumar Sahni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>ECMB0000010000003</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Wonderful device and smart phone best camera b...</td>\n",
       "      <td>125</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>Flipkart Customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>ECMB0000010000004</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Very good mobile. Value for money. Battery bac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Amit Sen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECMB000001</td>\n",
       "      <td>ECMB0000010000005</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Really great.... value for money...</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>Sudeshna pakira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6e89ba9-7ab7-405f-b83b-5759be9b3de5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e6e89ba9-7ab7-405f-b83b-5759be9b3de5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e6e89ba9-7ab7-405f-b83b-5759be9b3de5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   product_id          review_id               title  \\\n",
       "0  ECMB000001  ECMB0000010000001           Excellent   \n",
       "1  ECMB000001  ECMB0000010000002     Worth the money   \n",
       "2  ECMB000001  ECMB0000010000003           Just wow!   \n",
       "3  ECMB000001  ECMB0000010000004      Simply awesome   \n",
       "4  ECMB000001  ECMB0000010000005  Highly recommended   \n",
       "\n",
       "                                              review likes dislikes ratings  \\\n",
       "0  Wow superb I love it‚ù§Ô∏èüëç battery backup so nice üëçüëç   740      160       5   \n",
       "1  Mobile So Good In Range Redmi 9a Has Miui 12 L...   355      104       4   \n",
       "2  Wonderful device and smart phone best camera b...   125       47       5   \n",
       "3  Very good mobile. Value for money. Battery bac...     0        0       5   \n",
       "4                Really great.... value for money...    90       15       5   \n",
       "\n",
       "             reviewer  \n",
       "0      Abhishek Saini  \n",
       "1  Dinesh Kumar Sahni  \n",
       "2   Flipkart Customer  \n",
       "3            Amit Sen  \n",
       "4     Sudeshna pakira  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKE-Bb7cN6Hr"
   },
   "source": [
    "We Got good amount of data for our task lets make sure that we need to remove nullity from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdAK4WmPN6Hs"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 2.3 Handling Missing Values </h2><a id = \"2.3\" ></a>\n",
    "\n",
    "Missing data are not rare in real data sets. In fact, the chance that at least one data point is missing increases as the data set size increases. Missing data can occur any number of ways, some of which include the following.\n",
    "\n",
    "- Merging of source data sets\n",
    "- Random events\n",
    "- Failures of measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "Yaa0kgoBN6Hs",
    "outputId": "ba46c309-b513-4330-9981-f75c1e95b06f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "plt.figure(figsize=(25, 20))\n",
    "msno.matrix(df, color=[0.2, 0.4, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLzInb4HN6Hs"
   },
   "source": [
    "\n",
    "We can handle missing values using lots of techniques like simple statistical methods, using machine learning models and many more but in this case majority of missing values are from ratings column and we will use that column as label column later so I don't want to fake out or ruin the original distribution of the label data specially so thats why I will be dropping the rows having missing values in column ratings. Dropping technique in never recommended but in this senario I am using it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O34g384sN6Hs",
    "outputId": "26bdce00-b6ab-4c1d-9fd9-63a7e33b380c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48488 entries, 0 to 287\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   product_id  48488 non-null  object\n",
      " 1   review_id   48488 non-null  object\n",
      " 2   title       48488 non-null  object\n",
      " 3   review      48488 non-null  object\n",
      " 4   likes       48488 non-null  object\n",
      " 5   dislikes    48488 non-null  object\n",
      " 6   ratings     48488 non-null  object\n",
      " 7   reviewer    48488 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping the rows with missing values\n",
    "\n",
    "df.dropna(inplace=True, axis=0)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "oEafkMlLN6Hs",
    "outputId": "4aac2442-b8ee-4661-b789-dd0cfa8077bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdAAAAKHCAYAAACB52pQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebitc/3/8ef7DBwilZA0KWSolEwlRRRpUpkrU4Y0EF9DqChKpogoOqkQ0oCUBqlvmZW+NOnXnExlKPN83r8/3p+lZXU7zj7DXmfv83xc17nsfa+19/XZ13W71+d+3e/P+xOZiSRJkiRJkiRJerQJwx6AJEmSJEmSJElzIwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdGkOiIjVI2L+YY9DkiRJkiRJ0swzQJdms4jYFLgM2NYQXZIkSZIkSRq7DNCl2e8i4GTgUxiiS5IkSZIkSWPWpGEPQBpvMvPGiPgf4G7gGOCBiPhqZt4z5KFJkiRJkiRJGgEr0KXZJJr27dLAj6kQ/UhgcyvRJUmSJEmSpLHFAF2aTbKJiO2Bs4BtgCuAB4DjgK0N0TW79D2skSRJkiRJ0hxigC7NgoiYMPD9msBRVOuW7TNzQ+ANVKB+LPDOiJgy6gPVuBERq0I9sDFElyRJkiRJmrMM0KWZFBFTMnPawOFlgAQuyMyb27ErgX2BH1Ebi24aEQuO3kg1XkTEHsD3IuJdYIguSZIkSZI0pxmgSzMhIo4ELomIia31ee//pUWB+YB/tffN1zq7XAucDiwEfB5412D1ujQDzgf+AezeWgUZokuSJEmSJM1BBnjSCLXg+3Jg18x8GJjYV4l+LtXzfF+AzHwgIia11/4KXAb8oL02WL0uPaaImJyZvwLeCkwD9oiIHcAQXZIkSZIkaU4xQJdGKDOnZeaZmXlRRLwe+FNELNJevgX4NLVh6CHt/Q+1EH114GZgm8w8diiD15jUwvGH2rc3AIcATwN2jYhtwBBdkiRJkiRpTpj0+G+RNB2LAosAF0fEWpl5e0ScBjwd2DsiVgGuAhYGtgf2zMxee5fIzBzWwDV29M6TiNgWOJjqq38d8Hzg4HYufakXonteSZIkSZJGW0RMbCv1pXElzFmkmdcqyzcFjgDuBlZrIfqzgHWBXYGlgJuAkzLzmPZzhpwakYh4JfB94EDgy9RqhlWAr1HV6R/LzJPbez2/JEmSJElDERFnAL/IzMOGPRZpdjBAl2ZSL6RsIfpmwOH0heh973sy9f/abe37CfY/1/RExKKZeevAsb2B9wJrZ+a1feffCsAlwO3AgZn5pdEfsSRJkiRpXtVfeR4RHwO2pO5ff5SZD033h6UxwB7o0kzqa5fxEHAmsBfwBOCKiHgiPPIh8i+gv22L4bkeU0RMBQ6MiCkDLz0MPInaQLT33smZeQ2wG7AYsHtEvGfUBitJkiRJmuf1hefPBuaj9ob7oeG5xgsDdGkWPEaIPgW4OiIW6X2I9Npp2FZDM+AK4OzMvC8iFuw7/jeql/7GETEly4N9r98BLA7cOYpjlSRJkiSJiNgX+AuwM/BPiwc1nhigS7OoI0T/ELAE8KbhjkxjUWaemJkXRMQmwPER8bx2/OvAWcABwIYRsTBARMwPPBX4LLBCZp4ypKFLkiRJkuZdP6XuWRcBVowIM0eNG5OGPQBpbtPrUd7334Uzc7pVvf0hetss44rM/H+jNGSNT88AtgbujYgjM/OPVA+5rwCnAl+LiF9Rm9S+G9gnM/8NbiIqSZIkSZpzuvZ2y8yLI2IasBCwB3AxcP4wxifNbm4iKvWJiNWp6vELM/PfEbENsDLw0f6NQafz848KLt0wVLMiInYBjgOmAp/IzL9GxGTgKOA1wNOBvwNfyMwjhzdSSZIkSdK8YGDD0GcAE4GHM/O6dmxV4EjgRcAmmXnB0AYrzSYG6FKfiPgg8BHqaelkauOL9wAnzGhFr9W/mp3apqCfAU6iQvQ/t+NLUefotMy8th3zgY0kSdIQDARK82XmA8MekyTNbgPXus8BqwPLAjcDJwJHZeb9EbEKFaK/BHhrZv5oWGOWZgcDdGlARJxDVfdOodpiHD6Cn30kPI+I1wOXZuZtc2akmlf0hehfAD6ZmX/qeI8PbiRJkoZgIFDandpr7OTMvHm4I5OkOSMiTgPWBg4FpgHPAvamQvQ9MvOeiHgp8ElgPWDdzPzJsMYrzSob+ktNRPT2BDiTCs8fACZExBPb69P9/2UgPH8/cC6wypwbseYVmXk88D5gG+BDvY1FB95jeC5JkjTK2grAXnh+OrVnzfzUSkFJGnci4g3AmsB21Gr946kcBSpnnAaQmVcCBwDfBm4awlCl2cZNRDXP6wXfbQPQAK4GdgQ2Az4GTIuIz7ee6J1Vvh3h+aeAHTPzh6P4p2gcy8zjI2Ii1VboVOC/qtAlSZI0unrt8yLii8AaVKB01eD+Sbba0+zk+aQhezYwH/C7zHwwIpYBfgicAXwgM++LiNUy82eZeUlEbJaZ9w11xNIssgJd87SB4HsD4KPAApn5hczcALgAOBjYKSIW6Xvvyr0q4I7w/Ghgl8z8whD+JM3l2kOamZKZxwIruwmLpLlde+AnSfOEiFiZqsbcG7gwM2+PiKUiYreIOCwi1sjMaY+3olWaERExqZ1P87dzT5pjHmNO92Rgocy8LiKWBK4Azgd2aq1bNgEOjYjnABieazzwA1zztL7ge1vqaekS1IdB7/WNqBD9IGDHiFg6It5CfTgsM/A7euH5zpk5dRT/DI0hfefLKyJixZn4+V+1n/f6LWmu1dfOYNdWlSRJ49nCwPOpFYKTI2JLalXr7sAOwP9GxEutGNasav32H4qIhYGzgeMi4pXDHpfGr4E53XLt8EXAvRFxEvAb4LtUeH5XC9TfBNwK/GsYY5bmBAMYzfMiYkPgGKpdy/6Z+YN2fDI8EqKfDxwGfB84herz9f2+37E3FZ7vZHiu6YmyBPBT4O29YzP6s72vvQGTNLeLiBdQn42va9/P9AocSZpb9F/L+goa/ghcAvyECpY+A5wMrAVsANwBvH50R6rxpq18fjgiFqIqfidT96hXDndkGu/65nQbtEO/AC4GtgX+Tq3Av71VnH8cWB/48GArK2ksC/ed07ysTYCPBV4AbJGZNw28PrHvieuHgAWBX2fmae3YBOApwOnA2Zl53GiOX2NDV+/8iDgA+B9gg8y8dCS/IyLWBm7MzD/OkQFL0kzo6scaEYcD7wJe0zaSkqQxa+DeYDLwpMy8uX3/YmArKiz/RWae144/DzgH+GRmnjqckWu8iIhJ1GaNTwa2Bq5v7VwWo3pS39Q7R6WZ9Thzug0z84qIWJQqLlwZ+CtwA7Ak8BzgDZl51agOWprDrEDXvG4+4GXArYPhOdRypYh4dvv6YKpC/ZHwvH2o3Apsbniux9IXfC/ed/gbwC+BPVtF+mMaCM/3oG7CnjqHhitJI9auU72N9PrbU30N+AuwS0Q8aSiDk6TZYCA8PwL4MfD7iDgnIjbPzKsyc28qKO+F508H9gHmp1YfSrNqIeBZwDcz8+8tPN8S+Dbwc+CciFhpqCPUmDYDc7qdImKxzLwV2BI4gGpfFdR5+ErDc41HBuiaZzzG0vEJwD+BZ0fE0zp+Zhkq4FwR/hOEtq+n9Y5l5m1zZtQaLyJiU+CnEbEbQGb+muq7vz6wRnvPf23Q0rFJ7aHAfpl52WiNXZIeT9916iTg0ojYtx2/gqqU2wJ4UXuPG4xKGnP6wvMzgU2AS4FPAk8Hjo6IT7X3PdTetw210nVjYJPMvHYY49bY1vGZORFYGlgxIjaPiC8BXwF+CxwPrA3sPKqD1Lgyg3O6Fdqx2zNzamZunZmbZOYnM/PPwxq7NCcZoGue0fdBsFbr4UVm3kttEroK8KbWT472vsnAa4GXA5NGf8QaLyJiPmA9YDngqIj4TkSsk5mfAb4DHBkRk9qKhwl9PzcYnh8NvDszPzeEP0OSpisinkhtpDcZODgiLoiINwOfAn5A7TfSW91lP3RJY05EbAWsSbUx+HBmHkptFLoE8FBvD6WIWAd4IzAFeFVmXj2cEWusa5+ZT4iI10TEwq3q9/3AdsARwLJUS8jtMvMgqi/1IkMcssaBGZ3TtfdO6vva+Z3GLQN0zVMiYingQuCIvhD9CGo50tFUtfkL27K3Xalq39My85fDGrPGnsGJQ2Y+AHyTWrq7H1U5cmhEfJlq5TINOLy9t7dcris83zkzvzBaf4ckTc9gVVxm3kFVJv0M2B64CfggcBbV6mCRtv/Do1Z0SdLcqiMMeiHVvvGyzLwvIlag5nhnAgdm5oMRsWxm/i+wL/D2zLxmVAetcWHgM/ZwqoXjhhExpbUUXQ54JfDWzDw/IiZExLLAUsDvR3/EGstmcU73UN/POb/TuOUmoprnRMRmwBeoyvP9M/M3EfEUagnmDu1td1EbAB2TmYe1n/uvjSCl6Wk3VXdk5vXt+y8BzwdeDWwI7EitcriBOud2ysyLBn7HbsCRGJ5LmktFxBuB32XmH9r33wQWz8xXRMR6wHuAtwB3An8HtvLBtKS53UDP80Uy8/aIOBZYJzNf2Fo9XkFVY+6QmXdFxLuoud7HMvOu4Y1eY1lbmfpQRDyB2ih0OWA34A/Ah4HvZObdvfvTtor6BcBRVKHOy/tDTWlGOaeTHpsV6Bq3upYPtUnGmcA2VID5iYhYITNvy8ydqGDz7cA7qJ2je+H5BMNzjUTrm/8b4LMR8XaAzNyWWlL5qcw8KzM3op7kTwKWpzYF6v18tBuzA4BdDM8lzY0i4k1UVdzxEbFTO/xO4CkRcXhmXpCZb6NuuG6jegXfOpzRStLj67XT6wvPT6F6/kIFmMtHxPbAZcAP+U94/jTq/uIpgPcNmintfvWhFopfCWwG3Ev1058AfBrYqFWi98LzI6gCsfuAtdrPu9+IRsQ5nTR9VqBr3GvtWG7NzJva970n9W8BTgfOAz76WL0JrTzXSAy0XtkO2ApYFfg6cAi1sc/mwGcz89z2vrWAJ2TmDzp+39KZ+ZfRGr8kTU/XZ2JEbEw9mH4N8C2qAm4tamn5Ma2VARGxMnBzZt4wqoOWpBkQEfO1tnuPVJ9HxKLAr4C3ZealETGFundYh1rNunGrBH4W8BFgA2C9zLSFhmZae4jzOeBlwFsy84/t+POAU6hNRHcDzqV6VL8RWJz6zH24V8E+lMFrzHBOJ42MAbrGlYh4SWb+X/s6qODycqpv3JGZ+c/eay1E34GanJwCfDozrxrS0DWGTe8hS0QsT61s+ARVtfRzYGWqH/q+HZOWCZk5zQc3kuY2A+0MJlHzyAfb98+mbrCOBq4F/gasCJyRmR8d0pAlaYa0zT9/BvwhMzftO74sFaCvnZk/a8fWpsLyNan7iCcBzwReArzWDUM1O0TE+VRL6de273v3r8sA3wcepNq5nNUflvd/VkuPxTmdNHK2cNG4ERFbAldGxDuhZhttonsasDvw/ohYYuDHzqU2WdkGODwinjyaY9bYN1Bxvn5EHBQRUyPiwIhYKDN/l5nHAytRE5BVqBuuvYGNB39fbxNRw3NJc5OBG62PUJtv/yAiToqIxTPzb21Ts5WAq4GnUX2AD4iIdYc2cEmaMU+mihveEhEn9h2fRPX6vbPv2MXAdlTLjJdQwdJVVMhueK5Z0jYDnY9qAzRfREzqb8fSqtHPp/qiHwKs3vu59rrhuabLOZ00cwzQNZ5cTe0U/fleiA6Qme+gKsz3B94XEU/rCyfnB34L7Ek9vf/XKI9ZY1xfeL4t1TPuFVRAvjNwVUS8pvUovJ7qrf9J4Kvtxxcb/RFL0sj13Wh9nbq+/av9Wxv4eUS8trU/uJnqjfkR6gE2wPVDGLLGsP6wqLXMkOaIFk5OaqtUP0HN03aIiN7eM5OovtL/6P1MZk7LzOsy8wPARlRrg31t26KZ0Qu+e9r59QB1//pK4O3tM7h/f687gCOpz+Ejej83OiPWWOecTpo5k4Y9AGl2yczfRsT+wN3AFyPigcz8anvtXW1P0f2pJ/nHUBPh9YClgFMH27sM5Y/QmDB4jrQe5p+kllGenJm3RMQqVLuW7YFL2pP+e4GzgLMi4ujMvHwY45ekGdFrKdX3/a7UKprNgEtbu6m3UZVLqwIXtJ+5n+oNfEFEfCAzbxnG+DU2DVTG7QlMiogvZ+aNQx6axpm2+eIFwIeA8zPzpog4ngoq942IO4GTgacCr46Im4D7qSK0BajNQn+XmdcM5Q/QmNfrVd4qzp8BTMnM37aXvw2cQd3XBnBaRDwILE8F61OpQrDPRMRqvRZDUhfndNKsM0DXmNcmFNE+EBakllW+Hjg5IqZl5tfgkRD9AeC9wKZUL6/VqQ1E/9n7fYbnejwd58hLgVuAb/VNKg4G/gwcnpl3997Ymyj3wvPByYwkDVtvI72Oa9OLqb0cftNutJ4LnEhVJR3Vv2y871rnjZZmWPtM7IXnpwOrUW0yXDWrOSGAPwGXwSMPb25oITrAvsDrqND8SKrP+bT27yHgAVr7DGmk2vXuoYhYmGorujywUEScDXygFeR8kjrfTgJ2oPqePwO4MzOnRsR2wF3ArcP5KzS3c04nzT5ORjXmtV7n0yLiXdRO0VsBv6QmxadFxDv63rsL8AHgJ8CNwM6ZeRg8EsRLjykiDouI3fu+711DXwqP9CQkIs4DXgC8NTN/0dq4HN3e81D/7zQ81+MZXNorzUkRsSDw44jYqu/YpLbB1IuAOzLz3xGxHLXK5ofUZ+m9EbF3RBwG/32tk2ZE7zOxtc9Yg1rFdXxrg/YI52yaHTLzzszcKjPvjIgjge0jYnI73z5LtXRZhAqZXgwsTl0HVwSeA6yQmX8Yzug1lrXVrNNa5fm5VEj+CWrTxtcD34yIZTLzl1QLja2B24F7qfvd1dt18K3AH4F/D+HP0FzOOZ00e1mBrnEhIl4OfBo4APhKW4K5LvB+atnbtLYRBpk5FZg6sETYKmBNV9QGtMtRfc6BR4Xfl1CbTr2M2hz0hcAbM/OXrapkLeCZrf/+TaM8dI1hA9epdYCFqYff3+lNZm07pdnsaVQ15rm9A33n2veBrduN2DHUJmY7ZubdEbE0tRT4+rbvw32jP3SNBxHxAmovkX2BCzMzI+IZwBZU5eU5mfljr32aGS1QOgnYJjPvj4jJ1D3xDtRGoXdHxNcy87r4z2ai+wGHZeZOwK29asyh/AEak3rXq1YUke3rSVQRzh3AAZn5f+31C4EvAV+OiG3bQ5pTI+LM1hudiFiJuud4JfCKzLxtGH+X5nrO6aTZKJx3ajyIiG2Ao4B12pP63vEXAp+hbsS2zMxv9r3mjZdGJCIWaE/kNwJekpkfb8dfQfUhXIxazrtmZv6tVZVsBXyc2lzq5GGNXWNP/4O9iDgNeBmwKLX58RXAp4BvZ+aDwxulxpO+G/zefw8D7s/MD7fXN6KqMp8O/DgzX9uOL0btA/EqYMPeahxpZkTE6tQN/9pURdwm1M397VSrvqcC62bmhUMbpMasiHgztR/NL4CX9wWSi1Dn3cLAPsCZmflgRCxFVQDvDXwjM7cYzsg1lg0W0bQHN5dRrYDuzMz1+16bQO3TdTK1+mHHzPx/fZ/Nq1EtSdcANu+/95V6nNNJs5/LwjVeLA4sBPwdqtcXQGb+CjgVmAx8vbV5ob1meK4Z0tdC4/5WUb438IGI2AsgMy+ibu4nUq2BVo6I9ajqueOAz/TCc5eda0b1hecnAq+gbpbWo9oDLUtNblcZ2gA1Hk2E+nyMiCWp8+2dEbFPO34ecBi1VHzxiNg5IvYFTgDeArzNGy2NRP9nYt9n7V+AH1FLyS+jWhp8kSqG2BC4CdhgdEeqceT7wHbAs4DL++4ZbqfOsXuAQ4HN+tq5HNf+bdCujdIMa9XiV7cV0wC04ofvUfs8vCgiVu57bRq1aeM7gaWBsyPimX33rr8DjgfWNzzXdDink2YzA3SNSb2brL4br29RE95DADLzgfZkH+rJ/ZXAd6nKJWlE+lq1LJqZdwLvoyqA3xsR+7X3HA/sQW3iczpwJrA+sFdmHgKPVBT74EbT1RciERErUpXnHwZ+mJk/o6owFwAuAq4eyiA1LvUt610uM2+kbt6vAXbpu9YdB+xG3cAfBGxObWC2VmZ6PmqGtRZV2b6eQhVDkJk3A7tSN/ZnAO/IzD2zNnz/N3AbtUm3NCJtHnYfdV59kGoJNBiir8Z/h+g3tO9710ZpJJ4AHJiZl0TExN7BzNwf2JNaVbNTRDyz77Vp1IPEXah72Rv6XrszM6/Igb0hpH7O6aTZzxYuGjP6W65ExALA/cB8mXlfqwo+mOqPeUJmfqS9bxK1aegawK5OejWzIuLV1JLflTPzrxGxPNV3//nAiZn5ifa+RYEnUUsy7203/PbZ13RFxELA6zLza+373nLLtagqzDdn5g8iYlngcqpP4XaZeU9EbAL8IDPvGNofoHEjIvan2hc8LzNvns61biKwSGbeFhHz9dogSDMiHr2/w1HUg8IVqYrzU6n9bB7u7zXdWmkcALwaWC8z/zac0WssGpyHtXuJLalg/DpgjYF2Lj8D5gM+BpxiuzTNqoiYn1oBcU5mHtV3fH8qvDwGODIz/973Wv/97yPXTWlGOKeTZi8r0DUmDEweNqYqfH8NXBgRW7e3HQL8FNg1Ir7bnqx+mgrWf9QLz22hoZm0ADAN2KhNYH9HbVL7O6pqpPck/9bM/FO7sb8ZHjl/Dc/VqV2T9gW+GhG7wKNaTAX1Wf3viHgS/wnPd2jh+Suo6qWXjP7INU7dANwHrAvQca3btx1/mNr4DMBgSSPSF55/lVoqfgGwPzAFOAI4rgWevfB8O+BY4M3AJobnGok2b+u1RdswIpbJzHuBrwB7UZXoV7SAs1eJviq1cnVPag4ojVjvnGqeQZ1T+0TEjr2DWXsqfZhaebPHQCV69n1teK6Rck4nzUZWoGtMaWH5iVQl8MPAUtQGF6dQE9xpwNZUb8PnANcCUzPz6PbzbhyqmRYRPwIWzszV+o4tR1WMLAN8sU2CpRGJ2vB4L+AdwPvbkspehdx3gBWom65vUKtp7oqIp1KVc8sCm2bmP4YyeI0LAw+qrwRuz8xX973ef637SmYeMJyRaryIiM2Aw4EdgAvbisLVqAeFnwL2ay351qKCpQWAfTLzmqENWmPOwGqHLwIvpKqAP94eRM9Pbfh+GHA9VYl+f3v/wsDimfmn4YxeY1FEPJkKy//UzrFFgG2oh4AvBQ6k+u3vn5kn9P3cftSKh1OBvXurWKWRck4nzRkG6BozWi/gbwNfppa33dUqN/eiNtP7dGbu3tf6YAngwcy8rf28LTT0uLoesvSWskXEq6he+ntl5nF959qywOeoSfF6mXnlEIauMWhggrsi8CGqFVV/iP52qlfrc6jWBb8AVgZ2BzYCXpWZvx790Wss61oK3net2xQ4CdgpM08fuNadTPVzXTczbx3C0DVGDX6+RsRHgU2ANTPzzohYgVpJeAGwfQueVsjMayJiaeC2VhksjVhEnEH1N98d+Flm3th3bZtCtXM5HPgr1f/3/uGNVmNZRLyL2vj9MOp69kvgYmCbzLw7Ilan2lGtwX+H6IcArwTW9r5VM8o5nTQ6DNA11+q40doA+Brwlsy8YOC9hwL/A6yamVc93u+SHk9EvBh4IDN/23fs6cA3gVuAzaglcdH6tK5AbS51zlAGrDGl10pq4Bo3BViMeiC4JbBbZh7bXtsZ2AlYiVpZ8wDV3mWrdJMfzYL2gObPmXlp37HnAd8DLsnMbaI2tu1d655HPZy+dkhD1hjUX8QQEYtm5q0RcTjwxsxcPiKWoTbn/gHVouqu1rblRdTmewbnmmkRsQNV9bs5cFm7lj2RWsk6KTN/FbWR6JbAF4GLMvOVQxuwxrR2bl0BPAVIqu3oplQVcG81RH+Ivl9mntj3872A0+IvjYhzOmnOsge65lp9VZm95UZPoFoYTGjHJ7YPAKjJ7j3ABu216Ppd0oyIiOdTVb5nRcShEbFkRMyfmTdQffVfRz2pnwZMaxPca3rhed95Kf2Xdn68hWo11Tt2OvChrI2jDgZOAz4dEbsCtOqkN1OtDk4A9gbWNzzXrIiIDakWaGdExAkR8cKIWKC1KzgS2Coi1u671kXWHg/eaGmG9D4P+8LzrwBvby//P2C5iHgPcCm1YXIvPF8C2BB4MtWyT3pcEbFwRHw+IhYfeOl5wN8y82JgYkS8HLiIemBzdUTsm7Vp3plUK7UdRnXgGjdaJfAdVM/ppwILUa347myB5SSAzLwC+Ci1cfJBEbFH73e08Nz9kzQizumkOc8KdM3VImILKkjamJpg/Irqk7nJwPuWp5b97p2ZXxrtcWp8GGin8XrgNcD2VMX5T4GDgLuBqcBk4O2ZecuQhqsxqlW5HQu8ldr8eF1qWfkbMvPn7T0rUO1cHlWJLs2Kx2hRtSawPtVj+kHgKurcAzga+BuwS2bePZpj1djWHjr3+khPbMHRIlQl5jsy8yctSDqbakX1E+BNrZXLs6kN9TYEXp2Zvx/Sn6ExJiLeSG2Qt3Fm3tN3/H+o9iwfBJ5PPcQ5mwo2V6XabazouabZoT04XI8KyBelHgTuA5yWmfdHxKT8zwbJqwLHAbcBG1n0pRnlnE4afQbommtFbZB3CnVTNTUzb4mI3YCjqArMPTLz3qjNf7ahJimbZ+ZPhzZojTkDoXnvJn9CZk5r59ZTqHNrbeDpVHj+YmBp6gbtl8Mau8aWgSWTU6gb99WpCe7rMvPygTYH/SH6ezPzs32/y7ZUGpF49EZ6C1Orue7JzAfbsSdSKxs2BJanNqx9GTCF6gf896EMXGNOREymih5uycz+lYHPAX5LrZ65uB1fE9ifemD9eWAR4GlU65YNXGWjGdE+U5+ZmX/o6/v7PuA7mfmXiFiSKoLYmFrtcG6vZUZEbEudg69qKw2lEXuseVnUZvBXAEvw6BB9ArWy+m7g2cC17d7D+Z0el3M6aThsM3EIWGUAACAASURBVKC5UkS8lVo+OQk4v6/K92tUxeZ2wCVtKfBJ1BPVYw3PNRID4fkbgBMj4vvAKRGxEjAhM28EdqHaAx1DVQuvSgUBzx3KwDXmRMSCwCXAiyJicmbeB/yLmsg+BKzbJsPT+pb3XkO1czkFOC5qUyraa95caYYN3GgdBpxH3dCfHxEvi4hF2pLzjwDrUH1Znw4sAzyD6rcvzaiFqXYsr2rtqXrXrElUu707e2/MzMuAHanq4OcCzwIupzbQMzzX42qfmV+n2u69uIXnq1NztqMjYqnMvDEzdwBeALyzLzx/CvAq4Hrq3JRGrFWUZ0RMioglIuK5fXO5e4E1gX8ChwKbt1B9UeB04N2Z+dc2/5vg/E6PxzmdNDxWoGuu06p+vwBsRT2VXyczr+x7/SlU1eZewJLAH4GzM/Ok9robrmhEImIbalXDd4AFqE2lnkVVnp+cmbf1vXcl4IXAQpk5dQjD1RgUtUHensBemXlnO7Y+VX3+UWBZ4DPAEZn54MDy3mWoZedHZeZvhvIHaFyIiDOBlwMnU22oXkp9nu4PnNQ7N9t7nwEsB1xnWwPNiBYYTWzVlU8F3k1d376RmZtFxLLAj4BVMvPmx/j5ac7hNFIRsQ/wLioI3z0zr4qIzam53U+B9w32+Y2IdYB3Uu3U1s7MX4/uqDUe9K1eXYi6f12Jupe4DtiiFeL0CikupwLMnwDPpFq7LNeb70kj4ZxOGn0G6Bq6x+jftRiwH7AbVZV0cP+HQO/nqGqmCX19Ng3PNSIR8VLgLKon9YmZeXtbCvcv4LvAtpl5a//T/oGf7zwu9RuoFvk08N3M/F77/snUOdgL0Q9tlUhPAF5PbXJ2p+eZRmpglc321E3V9tReItMiYjXqhv7jwEGtctNrmkasXa8upHqXn9eqMRcDdqZC9C9Tn7MXUcH69cD9wEQqbHoS8PvM/L8hDF9j1MA17r3UfcMNwK6Z+cuovZQ+D1wAvL/XtiAidqRWPswHbG07Ps2M3vnXwvPLgVuphzYTqGveb6n2or9p718Q+ArVHvIfwFaZ+ZCfu5oRzumk4Zs07AFo3jbwQfB86gbqIeBqatnRgsAewLURcVJbBtcfRj3Yesj1fpfhuaar44HN4u2/38/M29vXpwN/Bz7SwvP5e/0KB88xJyV6LP3nWl94vjxVLfK2iHgHcElm/qu1rfomtZHZ/BFxGrA78CZgjcz891D+CI1ZHTdNSwJ3ANe0G61lgO8BXwU+0W60FsrMu+zBqpnwIP/Z6D1bq6qbI+LE9npvKfmDwIFUz99pwMPUvO9Bqs2BNBITqHMI4FxgLarV3rERsUtmnlH1Nny+HeuF6FdTeypdZC9gzYy+8HwSFZbfCGzZrntfB24CFgLOjYg3ZOZvM/OeiNgEeAJVGJH9Kw6lx+KcTpo7WIGuuUJEbE31+l0MeAD4PfB+qopkP+rp6u7UcqR7hzVOjR+tbcuqVAXcFpn5jHb8PKpH5hsz8+qIeDV1/u2UmfbH1AxpK2Q2AV6QmQe0Y+cB91LVmJ+lAqR3Ahe3ie5TqIc3r6DaV0FtLnrl4O+XZlR7GHM9tYnUopn58tZK43JqdcMO7QZrd2qD5B0z84HhjVhjSau83CAzv9F37NNUe72pWZu9LwHs1P79i7rGTaMCgHuBu4D5MvOfoz1+jV0DRTjfoAoinkTN61ahVkS8LzN/1VeJfj5ViX69oZJmVi/0jtqo8fnAO4BvZ+b5EfFVqlDizVSblm8Av6HuNa4Z+D2egxoR53TScLmJqIaihUu9r18LHE8taXsH1et3EnAOsAa18cVpwGHAjm35mzQiA+fcetQ5dxXwM2CJiNiiVYy8EHhzC88XpEL2JYElhjBsjV3zUQH5XhHxhYg4m3owc2hbKr4DtcrhFGCtiJgvq9f+psB7qArNlxmea6RaNVzv6/2psPIrwLeBl0TEHtSGtudTDwbvar0xV6EqOSeP/qg1hh0AfK09lO6df5tTFedbRMQCmfkPYCrV2uAFwAmZeVdm/gG4KTP/bXiukeoLzw8FXgnsA7w6M1elzr9lqKrzlTLzDKpH+sbA4S0ANbjUTGnh+UJUYLkx9bDmRxGxA9WHeqvM/EVmngNcTN1b/Dwilh74PZ6Dmi7ndNLcxRYuGoq+Se+S7dCpwMcz8652/GwqWDqceor/Hup8PRr4X8BehRqRgXMuqeWWZwCLUpuafYGqhHtxZl4XEVOAzaiNH/fLzL8MZeAak1rLn89TD14+QJ1ba2fm1e31a1r/wpOoa907I+KizLyDOjelmZL/2Xx2Nara9+isDfXuA64EPgn8LDM3b+9bEvgYFUC9JjPv7v7NUqdPUVWWX2xtW6ZGxLOBy6jCh4iI0zPzxnZNBNg/Is7LzI1sXaBZEdV7fxVqHndp73hmHhwR9wOHAsdHxHsz88yIeAj4reedZsZAu5VjqFXTJ1AbM06LiNWp1dP996l3AZ9rXz9qI1vp8Tink+YuVqBraCLi5dQSpFOAB3vhOUDWjuW7U73j9m2tM/YEXptu9KOZ1HfOnQ7cn5l3Z+a11CT491QP1s0iYivgoHb86Myc2n4+un+z9N/6eurfBQR1TQMeWbZ7DdUe6O9UkL5ub08HaVZEbaZ3OdXj926AzPwdcAjV+3e5iDistdqYCrwReFNm/n5IQ9YY1eZru1FtCk6MiJ2yNnZfk+oJfCiwZV8l+onUebl6RCw1rHFr3LgfWBh4UjYRMRkgMw8HvgWsDJwaES/IzG+2a6E0Yr3K84h4I/BP4LOZeW0LzycBT6faCE2MiEmtL/VCwPcy8z2Z+XBETBzin6AxyDmdNPfwRl3D9Gfg69RGKktAhUq9ACkzfwVcQy3BJDNvyswftvd57mpm9J9zT+0dzMzvUJvVnk0tAT4CWBHYPTM/AXXOudRSM+EzwOuoFQ5vjogvQ62IGAjRbwWOBaYMbaQaT84CTqZW26zUO9iudbtS1XAbAS8B/gCs1VsdIY1UC8bfR4Xon+sL0Vfj0SH6lNaq5Shg+cy8fmiD1ngxDfg58KKIWBcgMx/sCykfps7BB4A7hzNEjRetkOYAqs3oHsC/2/FeZfohwLLUpvBTqXuOBYHv9H5HPnojSGlGOKeT5hJuIqqhioinUct/t6A29Tmu77Up1ATl7vb6gwaYmlXtnDuK6tH6nsz8XN9rQVWOQN+qiBaeTxv1wWrciIjFgP2BbYBvZWavX/B8VPB0BfDXzLxueKPUeNKudUdTrah2zszPD7w+uQVNXt80W7TNQj8DvA14d2aeGBHzU3uNPJXaLP6kzLxviMPUOBMRz6c+Q68APpKZl7bjiwLHAV8ELs/Mfw9vlBov2sqZg4CtgSMy84Pt+MRWYf4GqgXpPVThzpatcn2i4blmlnM6ae5ggK6hG7jh+jDVl3oC8Cpq4vvuzPzi8Eao8WbgnNupr0XLI70NexOQViXshVKzLCIWB/YDtgW+R1UqvRfYDlixbagnzTbTu9YBD/ethPAap9liOiH6H6l2Gy/ta28lzRYR8RqqSvM64Dzgr8D61IZ7L3UfG81OA2Fm/2drtM/VBdtb723f9/dOl2aKczpp+NxEVEOXmf+IiPdRyzAPAt4P/B9VrXRgLzz3A0GzS985B9WzdVpmntQ/ue09vfec0+ySmf+MiE9QIdIuwGupzUVXNzzXnDCD1zqvcZptBs65z7VzbmrrBbyU4bnmhMw8PyLWBI6kVhhOpPa8WcfwXLNbZt4UEbtR59mJEUFmTu0Ly+/pvbfdvxqea5Y5p5OGzwBdc4X2gbAbFSxtTu0m/ZHe6y5H0uzWNwl5GJjaNjg77vF+TpoVfSH6OcDSwEWZ+bchD0vjWN+17iHqWvdgZp4y7HFp/Br4fD2xnXNfptoZSHNEZv46It5C9ZxeGLjNBzaaU2YkzGzvM9DUbOOcThouA3TNNdrT/H2A+YEPRcS1rWrJ8FxzRJuEfABYBJg87PFo3tBu6C9p/6Q5rl3r9qAeUl857PFo/Gvn3O7AfVQPdGmOa5W/9wC3DHssGv8GVlFPjYibM/PcYY9L45tzOml47IGuuU7r73UMsCnwgcw8ZshD0jgXEQv2L7eUpPHITcw02jznJI13EbEktafNgbZr0Wjx81UafQbomiu1EP004KbMfPuwx6N5g332JUmSJM0MNwyVpPHLAF1zrYh4YmbeMexxSJIkSZIkSZo3TRj2AEZbRGwSEcdGxIURcUdEZEScOuxx6b/1wvOIiGGPRZIkSZIkSdK8Z17cRPRDwMrAXcB1wPLDHY4ejy01JEmSJEmSJA3DPFeBDuwOLAc8EdhlyGORJEmSJEmSJM2l5rkK9Mz8ce9rO4NIkiRJkiRJkh7LvFiBLkmSJEmSJEnS4zJAlyRJkiRJkiSpwzzXwmV2WXVn3NhSo+aEPeq/O39quOPQvMNzTqPNc06jzXNOw+B5p9HmOafR5jmnYfn5CYzHPs1zffb48vfCluvB+9867JHMkJk+R6xAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOkwa9gBGW0RsDGzcvn1a++/LIuJL7etbMnPPUR+YJEmSJEmSJGmuMs8F6MCLgW0Gjj23/QP4G2CALkmSJEmSJEnzuHmuhUtmHpiZMZ1/zxn2GCVJkiRJkiRJwzfPBeiSJEmSJEmSJM0IA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuSJEmSJEmS1MEAXZIkSZIkSZKkDgbokiRJkiRJkiR1MECXJEmSJEmSJKmDAbokSZIkSZIkSR0M0CVJkiRJkiRJ6mCALkmSJEmSJElSBwN0SZIkSZIkSZI6GKBLkiRJkiRJktTBAF2SJEmSJEmSpA4G6JIkSZIkSZIkdTBAlyRJkiRJkiSpgwG6JEmSJEmSJEkdDNAlSZIkSZIkSepggC5JkiRJkiRJUgcDdEmSJEmSJEmSOhigS5IkSZIkSZLUwQBdkiRJkiRJkqQOBuiSJEmSJEmSJHUwQJckSZIkSZIkqYMBuiRJkiRJkiRJHQzQJUmSJEmSJEnqYIAuSZIkSZIkSVIHA3RJkiRJkiRJkjoYoEuS9P/bu/eQ7++6juOvd2qKeQpn1B+lVESOEE9NmmYeC0+ZZbQ/ZKWogyw1zanDdGqKx0izcOBhmpWSeVpq2magW6WOEEZqJZtQosZcyZaba+7TH9/f4PLidd/3tcvpvebjARffXd/j5/ruv+f94fMFAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAABFQPggAACBVJREFUACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoBHQAAAAAACgEdAAAAAAAKAR0AAAAAAAoDh3QZ+ZxM7N2P08sx283M2fMzKdm5r9n5qszc9HMvHhm7nSA+58wM1/c3f/8o5z3iJn58Mz8x8xcOTMXz8xfzszPHOH8W87MU2bmEzNz6cxcMTOfmZnXzsydr99bAAAAAAC4fmbmZrtOesnMXLXb/v7M3Px4j+2m6rDv/FD/Q2bmh5O8LskVSW5Tjt8+ySeS/ESSC5O8eXfo/kmel+Q3Zubea60vH+UxZ7V773vOy5OcnuQrSd6T5NIkP57k0Ul+ZWZOXWu9bc/5N09yXpL7Jvlskr9I8vUkP53kt5OcOjMnr7U+fdQXAAAAAABweM9O8pQkv57koiR3S/KWbK3yxcdxXDdlh3rn1zugz8xkC+JfSfKuJL9bTntytnj+5rXWE/Zdf/ZukKcledERnnFqkl9O8ptJ/uQI5/zg7tlfTnK3tdZ/7jn2wCQf2d3/bXsue0y2eH5ekp9fa12755oXJnn+7p7fNGYAAAAAgBvQyUnOWWuds/v98zPzviT3OY5jOrCrr0mu+UbyoU8mt7h58oSHJ9974587f6h3fpglXJ6a5EFJHp/kf45wzo/utueUY+/bbesyLjPzI0lem+SNST54lHHcOdv4P743nifJWuvvklxennHduN6/N57vvPdo4wIAAAAAuIGcn+SBM/OTSTIzJ2Zrrh84rqM6gKuvSX7hWcm1K/nSZckb3r/9fvU1x3tkx3Sod369AvrM3DXJy5K8Zq310aOc+s+77SPKsUfutueW+0+Ss5N8NckzjjGcf0tydZKTZuaEffe5f5LblmdcN66Hzcz+v/2I4wIAAAAAuAG9PMmfJvn0zPxvtm75lrVWXY3jxuRNH0gu/9o377v8a9v+G7lDvfNZax3o7rv1w/8xW5i++1rrypk5M8kLkjxprfWGPefeKtsyKSdnWwv9gt2hn01yYpKXrLVeWp7xO0lenW15lXNn5i5JLklywVrrfuX8pyf5g2xrn78n27IyP5bkF5N8NMnj9i3tMknemW15mE9ni+VXJ7lXkvsleX2SZ6y1bvz/XgIAAAAA/L80M6ckeWWSZ2ULuXdP8pokz1prvfF4ju1Y7n1azk3y4HLo3AvPykO/0+M5qMO+8+uzMs3zk9wjyf3WWlce7cS11lUz86DdAE5LctKew+/MFrv3/wEnJnlpktevtQ40C3yt9Ycz8/kkb0rypD2HPpfk7LK0y5qZx2aL/s/LFvOvc16SPxfPAQAAAIBvs1cmedVa6+273y+amTsneW62pa1vtC48Kw853mM4pEO98wMt4TIz90lyRpJXr7X+4QDn3zHJh5L8UpJTkpyw+zkl2yz0j8/MSXvOv0W26fNfTHL6Qca0u+70bEH+7Gwzz78v22zyi5P82cy8Yt/5t0ryjiTPzPbF1R9KcvskD8+2pvpHZ+bRB30+AAAAAMAh3DrJN/bt+0YO981KDuZQ7/yYM9B3S7e8Ncm/Jvm9Aw7m1Ul+Lsmj11rv27P/HTNzVbYZ6K9I8oDd/udmm93+wLXWFQd5wMw8INu6Ne9ea+1dL/2fZuYxu/E+c2Zev9a6eHfsOUl+NcnT1lpn7bnmg7uZ6Z/KNmv+vQEAAAAA+PY4J8lzZuaSbMuJ3CPbNyHfelxHddN2qHd+zDXQZ+YOSf7rgIN4zVrr6TNzaZI7JrndWuvyffe7XbaPhF6x1rrtbt97khxk5vdX11p32F3zqmwzyZ+61vqjMu53JXlMkseutf5qt+/CbDPU77bWuqhcc1mS709ywlrrKwf8mwEAAAAADmxmbpvkxdn65Q9kW5nj7UletNa66niO7abqsO/8IGugfz1HXgPmntlK/flJ/iXJdcu73HK3vVOSy/ddc6fd9uo9+/4224dA97tNkl9L8uUkf51k7/dd9z6jac854jUzc8tsH0jdfw0AAAAAwA1mN+n46bsfvgMO+86PGdB3Hwx9Yjs2M2dmC+hvWWu9Yc+hjyV5WJIXzMzj11rX7s6/WZIX7s45b88z/vgI979LtoD+ubXW/jF8LMlvJXnyzJy11vrCnuseluS+Sa5K8vf7rvmpJGfMzAVrra/vOXZmtvfxyf2z5gEAAAAA+O5zkBnoh/HsJCcnOTXJvWbmI7v9D05yYrbZ5md8i894Z5JzkzwkyWdm5t1JvpTkrkkemWSSPGffUiwvSfKo3Tg+OzN/k+TKbLH9pN1/P+1bHBcAAAAAADcB35aAvta6aGbukS2kPzTJaUlWkn9P8rokL9s7Y/yQz7h2Zh6e5ClJTsm2ds2tk1yW5ANJXrvW+vC+a74wM/fcjesRSR6f7SurX0xydpKXr7U++62MCwAAAACAm4ZjfkQUAAAAAAC+G33P8R4AAAAAAADcGAnoAAAAAABQCOgAAAAAAFAI6AAAAAAAUAjoAAAAAABQCOgAAAAAAFAI6AAAAAAAUAjoAAAAAABQCOgAAAAAAFD8H1iYPtpC2yNpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "plt.figure(figsize=(25, 20))\n",
    "msno.matrix(df, color=[0.2, 0.4, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvhL01cON6Hs"
   },
   "source": [
    "I Guess We are done with Data Acquisition task lets move to the next phase of the natural language processing **Text-Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XF4tsNCWN6Hs"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">3. Text Cleaning </h1><a id = \"3\" ></a>\n",
    "\n",
    "Text Cleaning is the process of extracting raw text from input data and converting it to the required encoding format by removing all non-textual material like markups and metadata. This is usually determined by the data format of the organisation (e.g., static data from PDF, HTML).\n",
    "\n",
    "Text cleaning is an important step in any NLP effort. And it may consume the majority of your project's time. We will discuss following techniques in upcoming subsections of text cleaning.\n",
    "\n",
    "- HTML Parsing and Cleanup\n",
    "- Unicode Normalization\n",
    "- Spelling Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuOQg51lN6Hs"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 3.1 Removing URLs </h2><a id = \"3.1\" ></a>\n",
    "\n",
    "URLs in the raw text can cause confusions to a NLP model and also they don't have any contextual meaning so better alternative is to remove these URLs from the raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZZk4Qc3N6Ht",
    "outputId": "a3fa92db-a4c5-4efa-9926-e01b727ecba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before removing url:- \n",
      " ‚Ñçùïö ùîºùïßùïñùï£ùï™ùï†ùïüùïñ ùïÄ ùïíùïû ùî∏ùïüùïúùïöùï• ùîæùï¶ùï°ùï•ùïí ùïôùïíùïßùïöùïüùïò ùï•ùïôùïñ ùïóùï†ùïùùïùùï†ùï®ùïöùïüùïò ùïÇùïíùïòùïòùïùùïñ ùï°ùï£ùï†ùïóùïöùïùùïñ \n",
      " https://www.kaggle.com/nkitgupta ùïíùïüùïï ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\n",
      "Text after removing url:- \n",
      " ‚Ñçùïö ùîºùïßùïñùï£ùï™ùï†ùïüùïñ ùïÄ ùïíùïû ùî∏ùïüùïúùïöùï• ùîæùï¶ùï°ùï•ùïí ùïôùïíùïßùïöùïüùïò ùï•ùïôùïñ ùïóùï†ùïùùïùùï†ùï®ùïöùïüùïò ùïÇùïíùïòùïòùïùùïñ ùï°ùï£ùï†ùïóùïöùïùùïñ \n",
      "  ùïíùïüùïï ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_url(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Example string with weird font characters plus an URL which we gonna remove.\n",
    "sample = \"‚Ñçùïö ùîºùïßùïñùï£ùï™ùï†ùïüùïñ ùïÄ ùïíùïû ùî∏ùïüùïúùïöùï• ùîæùï¶ùï°ùï•ùïí ùïôùïíùïßùïöùïüùïò ùï•ùïôùïñ ùïóùï†ùïùùïùùï†ùï®ùïöùïüùïò ùïÇùïíùïòùïòùïùùïñ ùï°ùï£ùï†ùïóùïöùïùùïñ \\n https://www.kaggle.com/nkitgupta ùïíùïüùïï ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\"\n",
    "print(f\"Text before removing url:- \\n {sample}\")\n",
    "\n",
    "sample = remove_url(sample)\n",
    "print(f\"Text after removing url:- \\n {sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igs2jMEiN6Ht"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 3.2 Unicode Normalization </h2><a id = \"3.2\" ></a>\n",
    "\n",
    "Before we go into what is Unicode Normalization lets first discuss why do we need unicode normalization. Consider the following example with some weird font:-\n",
    "\n",
    "String 1 : ‚Ñçùïö ùîºùïßùïñùï£ùï™ùï†ùïüùïñ ùïÄ ùïíùïû ùî∏ùïüùïúùïöùï• ùîæùï¶ùï°ùï•ùïí ùïôùïíùïßùïöùïüùïò ùï•ùïôùïñ ùïóùï†ùïùùïùùï†ùï®ùïöùïüùïò ùïÇùïíùïòùïòùïùùïñ ùï°ùï£ùï†ùïóùïöùïùùïñ ùïíùïüùïï ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\n",
    "\n",
    "String 2 : Hi everyone I am Ankit Gupta Having the following Kaggle profile and I am üòä to create this notebook. \n",
    "\n",
    "Above string 1 is written in some weird font and it also have an emoji so these kind of things can easily confuse a NLP model because model will treat both string 1 and string 2 differently although they represent same semantic meaning. To overcome this problem we do **unicode normalization**. \n",
    "\n",
    "We need to handle these kinds of characters because many people on their social media posts use these kind of fonts. And primary source of data used in any NLP task is social media.\n",
    "\n",
    "Now we are good to discuss how we do **unicode normalization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z07ojQP2N6Ht"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjgWeR3qN6Ht"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 3.2.1 The Issue of Equivalence</h3><a id = \"3.2.1\" ></a>\n",
    "\n",
    "When two or more characters have same semantic meaning but their representations are not same then we call it the **issue of Equivalence**. It is of 2 types compatibility equivalence, and canonical equivalence.\n",
    "\n",
    "**(a) Compatibility Equivalence**\n",
    "\n",
    "We identify compatible equivalence among a wide range of characters, some of which are abstract and others of which we see frequently.\n",
    "\n",
    "\n",
    "| | | Equivalence Reason |\n",
    "| --- | --- | --- |\n",
    "| ‚Ñå | H | Font variant |\n",
    "| \\[NBSP\\] | \\[SPACE\\] | Both are linebreak sequences |\n",
    "| ‚ë† | 1 | Circled variant |\n",
    "| x¬≤ | x2 | Superscript |\n",
    "| x‚±º | xj | Subscript |\n",
    "| ¬Ω | 1/2 | Fractions |\n",
    "\n",
    "In Above table words are having different characters representations but same semantic meaning. Our Objective is that model treats both \"ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\", \"I am happy to create this notebook\" the strings in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-a5mR9sN6Ht"
   },
   "source": [
    "Consider this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDDNiGNMN6Ht",
    "outputId": "c42f82ad-38ae-4da9-a717-0134b7ad6245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√á CÃß\n"
     ]
    }
   ],
   "source": [
    "print(\"\\u00C7\", \"\\u0043\\u0327\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqiPjETzN6Ht",
    "outputId": "5b73b1f1-34ac-44a2-90dc-63731cc97f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\u00C7\" == \"\\u0043\\u0327\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnyokzjRN6Ht",
    "outputId": "3f9abf9a-ab5d-4a19-e90d-e01ae9655656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"√á\" == \"CÃß\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXCLR4CcN6Ht"
   },
   "source": [
    "**(b) Canonical Equivalence**\n",
    "\n",
    "Canonical equivalency is more difficult to discover since it involves characters which appear to be identical when rendered but are actually wholly separate characters.\n",
    "\n",
    "| | | Equivalence Reason |\n",
    "| --- | --- | --- |\n",
    "| √á | C‚óåÃß | Combined character sequences |\n",
    "| Í∞Ä | ·ÑÄ ·Ö° | Conjoined Korean characters |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_877bavN6Ht"
   },
   "source": [
    "Our approach to canonical and compatibility equivalence difficulties is Unicode normalisation. There are two sorts of conversions and two directions for normalizing. Canonical and compatibility are the two sorts we've already discussed. Decomposition and composition will be what we gonna do.\n",
    "\n",
    "**Decomposition** :- In Decomposition we Decompose the character into many forms. So in the case of our CÃß with cedilla we would break both versions of the character down into the two separate characters (Latin capital C + combining cedilla).\n",
    "\n",
    "**Composition** :- In Composition we merge them into one. In the case of our CÃß with cedilla we would merge both versions of the characters up into the one separate characters (Latin capital C + combining cedilla).\n",
    "\n",
    "We get four possible normalisation forms when we combine these two directions with our two conversion types:\n",
    "\n",
    "| Name | Abbreviation | Description | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| Form D | NFD | *Canonical* decomposition | `√á` ‚Üí `C Ãß` |\n",
    "| Form C | NFC | *Canoncial* decomposition followed by *canonical* composition | `√á` ‚Üí `C Ãß` ‚Üí `√á` |\n",
    "| Form KD | NFKD | *Compatibility* decomposition | `‚Ñå Ãß` ‚Üí `H Ãß` |\n",
    "| Form KC | NFKC | *Compatibility* decomposition followed by *canonical* composition | `‚Ñå Ãß` ‚Üí `H Ãß` ‚Üí `·∏®` |\n",
    "\n",
    "In this notebook I Will be using NFKD approach this is the one we use more frequently in NLP.\n",
    "\n",
    "For the more detailed understanding of the above mentioned composition decomposition approach read this beautiful blog post about\n",
    "\n",
    "[What on Earth is Unicode Normalization?](https://towardsdatascience.com/what-on-earth-is-unicode-normalization-56c005c55ad0) By James Briggs on Towards Data Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AF4bLs1-N6Hu",
    "outputId": "d9c9f631-8c3f-45d0-b5b7-08a51c04fea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before Unicode Normalization:- \n",
      " ‚Ñçùïö ùîºùïßùïñùï£ùï™ùï†ùïüùïñ ùïÄ ùïíùïû ùî∏ùïüùïúùïöùï• ùîæùï¶ùï°ùï•ùïí ùïôùïíùïßùïöùïüùïò ùï•ùïôùïñ ùïóùï†ùïùùïùùï†ùï®ùïöùïüùïò ùïÇùïíùïòùïòùïùùïñ ùï°ùï£ùï†ùïóùïöùïùùïñ \n",
      "  ùïíùïüùïï ùïÄ ùïíùïû üòä ùï•ùï† ùïîùï£ùïñùïíùï•ùïñ ùï•ùïôùïöùï§ ùïüùï†ùï•ùïñùïìùï†ùï†ùïú\n",
      "Text after Unicode Normalization:- \n",
      " Hi Everyone I am Ankit Gupta having the following Kaggle profile \n",
      "  and I am üòä to create this notebook\n"
     ]
    }
   ],
   "source": [
    "import unicodedata as uni\n",
    "\n",
    "print(f\"Text before Unicode Normalization:- \\n {sample}\")\n",
    "\n",
    "sample = uni.normalize('NFKD', sample)\n",
    "print(f\"Text after Unicode Normalization:- \\n {sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTr3BM2dN6Hu"
   },
   "source": [
    "We successfully removed compatibility equivalence from the above example ü•≥ü•≥. Our Next Task is to handle these emojis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMrTHJ6JN6Hu"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 3.2.2 Handling Emoji ‚Äòüòçüòç‚Äô & Emoticon ‚Äò :) ‚Äô</h3><a id = \"3.2.2\" ></a>\n",
    "\n",
    "We need to handle emojis because they store lots of important information about the sentiment of the text we dont't want to lose this information by just removing them from the text. There are lots of ways to handle them in this notebook I am replacing them with their English version using python library \"demoji\".\n",
    "\n",
    "**What is an Emoji ü§î?**\n",
    "\n",
    "Emojis are small digital images or icons that are used to convey a message or emotion. These are small enough to be inserted into a text document. \"e\" stands for image, while \"moji\" stands for character in Japanese.\n",
    "\n",
    "Consider the example of Emoji Handling \n",
    "\n",
    "\n",
    "I ‚ù§ üçî so much \n",
    "\n",
    "English version of above comment is\n",
    "\n",
    "I love burger so much\n",
    "\n",
    "**What is an Emoticon ‚Äò :-) ‚Äô?**\n",
    "\n",
    "An emoticon is a combination of the words \"emotion\" and \"icon.\" It is a keyboard depiction of a facial expression, such as a smile or frown, that is used to indicate the writer's feelings or intended tone.\n",
    "\n",
    "Examples-\n",
    ":-)   Smile\n",
    "\n",
    ";-)   Smile with a wink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zgtR-FLN6Hu",
    "outputId": "9cdded9a-9ca6-4cd2-cdf1-15f8eda58917",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: demoji in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-1PjQ2cN6Hu",
    "outputId": "91de4671-0c98-4214-9660-f006e72d4fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Handling emoji:- \n",
      " Hi Everyone I am Ankit Gupta having the following Kaggle profile \n",
      "  and I am üòä to create this notebook\n",
      "After Handling emoji:- \n",
      " Hi Everyone I am Ankit Gupta having the following Kaggle profile \n",
      "  and I am  smiling face with smiling eyes to create this notebook\n"
     ]
    }
   ],
   "source": [
    "import demoji\n",
    "\n",
    "\n",
    "def handle_emoji(string):\n",
    "    emojis = demoji.findall(string)\n",
    "\n",
    "    for emoji in emojis:\n",
    "        string = string.replace(emoji, \" \" + emojis[emoji].split(\":\")[0])\n",
    "\n",
    "    return string\n",
    "\n",
    "\n",
    "print(f\"Before Handling emoji:- \\n {sample}\")\n",
    "print(f\"After Handling emoji:- \\n {handle_emoji(sample)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS6EuAB2N6Hu"
   },
   "source": [
    "For the more detailed understanding of the above mentioned emoji handling approach read this beautiful blog post about\n",
    "\n",
    "[How to handle Emoji ‚ÄòüòÑ‚Äô & Emoticon ‚Äò :-) ‚Äô in text preprocessing?](https://medium.com/geekculture/text-preprocessing-how-to-handle-emoji-emoticon-641bbfa6e9e7) By Paritosh Mahto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7SpVuzBN6Hu"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 3.3 Spelling Correction </h2><a id = \"3.3\" ></a>\n",
    "\n",
    "Due to fast typing or fat finger typing many people experience spelling mistakes. For a NLP model understanding of the context is very important is spelling got wrong then whole context of the text may get wrong. We will do spelling correction using pyspellchecker a python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gigiFfxCN6Hu"
   },
   "outputs": [],
   "source": [
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# spell = SpellChecker()\n",
    "\n",
    "# # Add misspelled words to the list\n",
    "# misspelled_words = [\"nsme\", \"mobiile\", \"phoone\"]\n",
    "# print(f\" Misspelled words before correction:- \\n {misspelled_words}\")\n",
    "# print(f\" Misspelled words after correction\")\n",
    "# for word in misspelled_words:\n",
    "#     # Get the one `most likely` answer\n",
    "#     print(spell.correction(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n3jCNkj5N6Hu"
   },
   "outputs": [],
   "source": [
    "# spell.correction(\"nsme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yDTlhrGyN6Hu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHCoqtqSN6Hu"
   },
   "source": [
    "For the more detailed understanding of the above mentioned Spelling Correction approach read this beautiful blog post about\n",
    "\n",
    "[Spelling checker in Python](https://www.geeksforgeeks.org/spelling-checker-in-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F-oM_MvN6Hu"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">4. Text Pre-Processing </h1><a id = \"4\" ></a>\n",
    "\n",
    "In the previous section we covered the text extraction and cleaning phase of a NLP project. Question may arise if we did the cleaning and extraction task then why do we need text-preprocessing phase. Answer is pretty simple any NLP project consist of modelling phase in which we train the model so that we can use it for real world data. And model needs numerical data but our data is textual so that's why we have to do various text preprocessing task.\n",
    "\n",
    "Below I mentioned few pre-processing tasks:-\n",
    "\n",
    "- **Preliminaries**\n",
    "    - Sentence segmentation and word tokenization.\n",
    "- **Frequent steps**\n",
    "    - Stop word removal, stemming and lemmatization, removing digits/punctuation, lowercasing, etc.\n",
    "- **Other steps**\n",
    "    - Normalization, language detection, code mixing, transliteration, etc.\n",
    "- **Advanced processing**\n",
    "    - POS tagging, parsing, coreference resolution, etc.\n",
    "\n",
    "above mentioned task vary according to the task or model we wil use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxT2VzCUN6Hv"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 4.1 Preliminaries </h2><a id = \"4.1\" ></a>\n",
    "\n",
    "Any NLP based task can be done by breaking the text into words(tokens) and sentences. So now we have to focus on breaking the text into sentences first (**Sentence Tokenization**) and then into words (**Word Tokenization**). \n",
    "\n",
    "But in our case we are not dealing with task with such a big textual data that need to be first break into sentences, in our case we already have the sentences so we just have to proceed with the word tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-Q45A69N6Hv",
    "outputId": "180b1b49-46b2-4040-a552-df9a87102f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Everyone I am Ankit Gupta.\n",
      "['hi', 'everyone', 'i', 'am', 'ankit', 'gupta.']\n"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "sample = \"Hi Everyone I am Ankit Gupta.\"\n",
    "print(sample)\n",
    "print(word_tokenizer(sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEyTXjtSN6Hv"
   },
   "source": [
    "For identifying specific patterns (e.g., dates or money expressions), well-formed regular expressions are the first step. In many practical scenarios, we may end up using a custom tokenizer or sentence segmenter that suits our text structure instead of or on top of an existing one available in a standard NLP library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DHbg2oMN6Hv"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 4.2 Frequent Steps </h2><a id = \"4.2\" ></a>\n",
    "\n",
    "Let's have a look at some more common NLP pipeline pre-processing activities. Assume we're developing software that classifies news articles into one of four categories: politics, sports, business, or other. Assume we've got a decent sentence segmenter and tokenizer in place. At that point, we'd have to consider what kind of data might be valuable in constructing a categorization tool. Some commonly used English terms, such as a, an, the, of, in, and so on, aren't especially beneficial for this purpose because they don't carry enough substance to distinguish between the four categories on their own. **Stop words** are words that are typically (but not always) eliminated from further processing in problem scenarios like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmUF_sXvN6Hv"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 4.2.1 Removing Stop Words </h3><a id = \"4.2.1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DsAg3tP-N6Hv",
    "outputId": "6bf05260-88e9-4e8b-b230-e63457b5e6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words in English : \n",
      "{'which', 'both', 'now', 'where', 'ma', 'down', 're', 'the', 'has', 'any', 'each', \"hadn't\", 'no', 'mustn', 'shouldn', 'wouldn', 'they', \"hasn't\", 'theirs', 'under', 'that', 'can', 'in', 'themselves', 'for', 'didn', 'again', 'is', 'and', 'ain', 'was', 'herself', 'its', 'who', \"you'll\", 'so', 'other', 'y', 'doesn', 'very', 'such', 'we', 'are', 'an', 'than', \"haven't\", 'then', 'do', 'while', 'been', 'this', 'what', 'with', 'aren', 'hadn', 'don', 'couldn', \"you've\", 'few', 'it', 'as', 'll', \"shan't\", 'am', 'after', \"you'd\", 'or', 'him', 'i', 'from', 'me', 'how', 'did', 'why', 'whom', \"should've\", 'between', \"mightn't\", 'her', \"isn't\", \"shouldn't\", \"it's\", \"wasn't\", 'have', 'most', \"weren't\", \"doesn't\", 'd', 'haven', 'off', 'won', 'ours', 'needn', 'itself', \"aren't\", 'further', 'will', 'into', 'wasn', 'mightn', 'too', 've', 'our', 'their', 'being', 'if', 'against', 'during', 'but', \"that'll\", 'all', 'them', 'o', 'own', 'same', 'on', 'not', \"wouldn't\", 'does', 'hers', 'through', 'his', 'a', 'here', 's', 'above', 'by', 'hasn', 'nor', 'yourselves', 'weren', 'those', 'she', 'over', 'these', \"couldn't\", 'isn', \"didn't\", 'at', 'about', \"mustn't\", 'before', 'were', 'out', 'should', 'be', 'until', 'you', 'to', 'just', 'shan', 'below', 'up', 'more', \"needn't\", 'himself', 'my', \"she's\", 'doing', 'm', 'of', 'yourself', 'he', \"won't\", 't', 'some', \"don't\", 'once', 'only', 'ourselves', 'because', \"you're\", 'there', 'having', 'when', 'myself', 'your', 'had', 'yours'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "print(f\"Stop Words in English : \\n{ en_stopwords}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLyfmigPN6Hv",
    "outputId": "2486e33d-3b11-4381-f789-276658a7ba7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing stopwords : ['hi', 'everyone', 'i', 'am', 'ankit', 'gupta.']\n",
      "After removing stopwords : ['hi', 'everyone', 'ankit', 'gupta.']\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in en_stopwords]\n",
    "    return text\n",
    "\n",
    "\n",
    "print(f\"Before removing stopwords : {word_tokenizer(sample)}\")\n",
    "print(f\"After removing stopwords : {remove_stopwords(word_tokenizer(sample))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHkBb0ILN6Hv"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 4.2.2 Stemming</h3><a id = \"4.2.2\" ></a>\n",
    "\n",
    "**Stemming** refers to the process of removing suffixes and reducing a word to some base form such that all different variants of that word can be represented by the same form (e.g., ‚Äúdog‚Äù and ‚Äúdogs‚Äù are both reduced to ‚Äúdog‚Äù). This is accomplished by applying a fixed set of rules (e.g., if the word ends in ‚Äú-es,‚Äù remove ‚Äú-es‚Äù). More such examples are shown in below Figure.\n",
    "\n",
    "![](https://user.oc-static.com/upload/2020/10/22/16033551309054_stemming%20example.png)\n",
    "\n",
    "This is accomplished by applying a fixed set of rules (e.g., if the word ends in ‚Äú-es,‚Äù remove ‚Äú-es‚Äù)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KccMzifcN6Hv",
    "outputId": "3f84b92f-0d83-4077-af66-50ae75b36348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Stemming : I am creating a Notebook\n",
      "After Stemming : ['i', 'am', 'creat', 'a', 'notebook']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# stemmer = LancasterStemmer()\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "sample = \"I am creating a Notebook\"\n",
    "print(f\"Before Stemming : {(sample)}\")\n",
    "print(f\"After Stemming : {stemming(word_tokenizer(sample))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0ghVJBsN6Hv"
   },
   "source": [
    "Stemming is just removing the suffix to get the base form of the word but the resultant word is not desired results, I mean to say when we will use word embeddings later then it may affect badly. So we need to look for the alternative for stemming and that is lemmatization it gets the word's base form on the basis of its context.\n",
    "\n",
    "![](https://stringfixer.com/files/107654628.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLwAb9jMN6Hv"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 4.2.3 Lemmatization</h3><a id = \"4.2.3\" ></a>\n",
    "\n",
    "Lemmatization is the process of mapping all the different forms of a word to its base word, or lemma. While this seems close to the definition of stemming, they are, in fact, different. For example, the adjective ‚Äúbetter,‚Äù when stemmed, remains the same. However, upon lemmatization, this should become ‚Äúgood,‚Äù as shown in Figure below. \n",
    "\n",
    "![](https://devopedia.org/images/article/227/6785.1570815200.png)\n",
    "\n",
    "\n",
    "Lemmatization requires more linguistic knowledge, and modeling and developing efficient lemmatizers remains an open problem in NLP research even now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "V0nteU1qN6Hv"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NMcXu6INN6Hv"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "sp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HanHY45YN6Hv",
    "outputId": "1ff3b1cd-55cc-4d62-c7f3-6af819568a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Lemmatization : ['i', 'am', 'creating', 'a', 'notebook']\n",
      "After Lemmatization : ['I', 'be', 'create', 'a', 'notebook']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "\n",
    "    # text = [sp(word).lemma_ for word in text]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    token = sp(text)\n",
    "\n",
    "    text = [word.lemma_ for word in token]\n",
    "    return text\n",
    "\n",
    "\n",
    "print(f\"Before Lemmatization : {word_tokenizer(sample)}\")\n",
    "print(f\"After Lemmatization : {lemmatization(word_tokenizer(sample))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1bJNEwIN6Hv"
   },
   "source": [
    "Keep in mind that not all of these procedures are always required, and not all of them must be completed in the sequence listed. When removing numerals and punctuation, for example, the order in which they are eliminated may not matter. However, Before stemming, we usually lowercase the text. \n",
    "\n",
    "And before lemmatization We don't take tokens away either. Because we need to know which part of the text to lemmatize, we must lowercase it first. To get the lemma of a word, it must be said, and all tokens in the phrase must be intact. \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Preparing a sequential list of pre-processing chores is a recommended practice to follow, must be completed once we have a firm grasp on how to handle our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__YZ7wr-N6Hw"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 4.3 Other Pre-Processing Steps </h2><a id = \"4.3\" ></a>\n",
    "\n",
    "\n",
    "In an NLP pipeline, we've seen a few common pre-processing processes so far. We have presumed that we are dealing with standard English text despite the fact that the nature of the texts has not been expressly mentioned. What makes a difference if this isn't the case? Using a few examples, let's explain a few more pre-processing processes to deal with such instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aayJdZXKN6Hw"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 4.3.1 Language Detection</h3><a id = \"4.3.1\" ></a>\n",
    "\n",
    "\n",
    "These day lot of information on web are multi language. But we assumed text to be in English only on that assumption we have constructed the pipeline. So what now, we just need to add another component to the pipeline at its start for **language detection**\n",
    "\n",
    "We can use libraries like Pycld2 for language detection. Once this step is done, the next steps could follow a language-specific pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5npfE5cN6Hw",
    "outputId": "de976999-295c-4a29-9598-1de68f69fc20",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32rgT4wgN6Hw",
    "outputId": "972dc747-6c79-4e1b-f2b2-b26a47ebe032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Hi Everyone I am Ankit Gupta. : tl\n",
      "‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§Ö‡§Ç‡§ï‡§ø‡§§ ‡§ó‡•Å‡§™‡•ç‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§π‡•Ç‡§Å : hi\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "\n",
    "en_text = u\"\"\"\"Hi Everyone I am Ankit Gupta.\"\"\"\n",
    "print(f\" {en_text} : {detect(en_text)}\")\n",
    "\n",
    "hindi_text = u\"\"\"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§Ö‡§Ç‡§ï‡§ø‡§§ ‡§ó‡•Å‡§™‡•ç‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§π‡•Ç‡§Å\"\"\"\n",
    "print(f\"{hindi_text} : {detect(hindi_text)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gtDKTvjN6Hw"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 4.3.2 Code mixing and transliteration</h3><a id = \"4.3.2\" ></a>\n",
    "\n",
    "In previous Section we discussion was about a scenario in which the content was written in a language other than English. Another instance is when a single piece of content is available in multiple languages. Many people all across the world speak multiple languages. Their daily routines As a result, they frequently use many languages. They use multiple languages in their social media posts, and a single post can contain multiple languages. As an example Consider a Hinglish (Hindi Plus English) phrase as an example of code mixing.\n",
    "\n",
    "![](https://www.researchgate.net/publication/353700736/figure/fig1/AS:1053290997485568@1628135551691/Example-parallel-Hinglish-and-English-sentences-The-code-mixed-Hinglish-sentences.png)\n",
    "\n",
    "\n",
    "**Code mixing refers to this phenomenon of switching between languages. When people use multiple languages in their write-ups, they often type words\n",
    "from these languages in Roman script, with English spelling.**\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "**So, the words of another language are written along with English text. This is known as transliteration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "A95zmYwKN6Hw"
   },
   "outputs": [],
   "source": [
    "# from googletrans import Translator\n",
    "\n",
    "# translator = Translator()\n",
    "# translator.translate(hindi_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_VvavGgN6Hw"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 4.4 Data Augmentation </h2><a id = \"4.4\" ></a>\n",
    "\n",
    "We had the highly biased data. In this case, if we just output that the review is positive then also we will get 95% accuracy. But before the data augmentation approach, we feed this data to a bi-lstm-based model and we got 60-70% of accuracy which was not acceptable. So we did the Data augmentation and generate more negative reviews to balance the data and after that, we got 96-97% accuracy. In this section, I want to discuss what kind of data augmentation we use and what tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cc_V_cTvN6Hw"
   },
   "outputs": [],
   "source": [
    "df_temp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-xpJlgBN6Hw",
    "outputId": "11f95736-1862-4e20-df83-a1f53ea6e04a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48488/48488 [00:00<00:00, 601862.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assigning labels to each review\n",
    "\n",
    "def label(y):\n",
    "    if y == '5':\n",
    "        return 1\n",
    "    elif y == '4':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df_temp['y'] = df_temp.ratings.progress_map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "P1B2b6ywN6Hw"
   },
   "outputs": [],
   "source": [
    "df_temp = df_temp[['review', 'y', 'ratings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hBqe_taxN6Hw",
    "outputId": "ca6c1fed-e372-474b-be0b-265df1459c60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a53746b4-7439-4fc5-b61f-c54f66f0cf16\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow superb I love it‚ù§Ô∏èüëç battery backup so nice üëçüëç</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mobile So Good In Range Redmi 9a Has Miui 12 L...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful device and smart phone best camera b...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very good mobile. Value for money. Battery bac...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Really great.... value for money...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a53746b4-7439-4fc5-b61f-c54f66f0cf16')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a53746b4-7439-4fc5-b61f-c54f66f0cf16 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a53746b4-7439-4fc5-b61f-c54f66f0cf16');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y ratings\n",
       "0  Wow superb I love it‚ù§Ô∏èüëç battery backup so nice üëçüëç  1       5\n",
       "1  Mobile So Good In Range Redmi 9a Has Miui 12 L...  1       4\n",
       "2  Wonderful device and smart phone best camera b...  1       5\n",
       "3  Very good mobile. Value for money. Battery bac...  1       5\n",
       "4                Really great.... value for money...  1       5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7Brpr9_N6Hw",
    "outputId": "d6ad5f1c-d02d-4635-b036-f48c4a23fbff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    44751\n",
       "0     3737\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "oGXx3fcbN6Hw",
    "outputId": "c33d7696-d8a9-404c-e3ee-5a15c34bc19c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPKUlEQVR4nO3df+xddX3H8eeLFtRlQ9B+g9rCSmazpbrNHw12859FMihus8SogcxRXWOXiIsmyzbcH2NDSXRzY+LUhEilJYuVqBudwTQN4swyEcpwYksI36GONmgr5YfOCCl774/7qbsr35bbT7n39vJ9PpKb7znv8znnvk/yTV45P2+qCkmSepwy7QYkSbPLEJEkdTNEJEndDBFJUjdDRJLUbem0G5i0ZcuW1cqVK6fdhiTNjLvuuusHVTW30LJFFyIrV65k165d025DkmZGku8ebZmnsyRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndFt0T69Jz2X9d9cvTbkEnoXP+/J6xbdsjEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUbewhkmRJkruTfLHNn5vk60nmk3w2yWmt/rw2P9+Wrxzaxvtb/b4kFw7V17XafJIrxr0vkqT/bxJHIu8F7h2a/zBwTVW9HHgE2NjqG4FHWv2aNo4kq4FLgFcA64BPtGBaAnwcuAhYDVzaxkqSJmSsIZJkBfBbwKfafIA3AJ9rQ7YAF7fp9W2etvz8Nn49sK2qnqiqbwPzwHntM19VD1TVk8C2NlaSNCHjPhL5O+BPgP9p8y8GHq2qQ21+L7C8TS8HHgRoyx9r439aP2Kdo9WfJsmmJLuS7Dpw4MCJ7pMkqRlbiCT5bWB/Vd01ru8YVVVdV1VrqmrN3NzctNuRpOeMpWPc9uuBNyV5I/B84HTgo8AZSZa2o40VwL42fh9wNrA3yVLghcDDQ/XDhtc5Wl2SNAFjOxKpqvdX1YqqWsngwviXq+p3gduAt7RhG4Cb2/T2Nk9b/uWqqla/pN29dS6wCrgDuBNY1e72Oq19x/Zx7Y8k6enGeSRyNH8KbEvyQeBu4PpWvx64Mck8cJBBKFBVu5PcBOwBDgGXV9VTAEneA+wAlgCbq2r3RPdEkha5iYRIVX0F+EqbfoDBnVVHjvkJ8NajrH81cPUC9VuAW57FViVJx8En1iVJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3cYWIkmen+SOJP+RZHeSv2z1c5N8Pcl8ks8mOa3Vn9fm59vylUPben+r35fkwqH6ulabT3LFuPZFkrSwcR6JPAG8oap+FXgVsC7JWuDDwDVV9XLgEWBjG78ReKTVr2njSLIauAR4BbAO+ESSJUmWAB8HLgJWA5e2sZKkCRlbiNTAj9rsqe1TwBuAz7X6FuDiNr2+zdOWn58krb6tqp6oqm8D88B57TNfVQ9U1ZPAtjZWkjQhY70m0o4YvgHsB3YC/wk8WlWH2pC9wPI2vRx4EKAtfwx48XD9iHWOVl+oj01JdiXZdeDAgWdj1yRJjDlEquqpqnoVsILBkcMvjfP7jtHHdVW1pqrWzM3NTaMFSXpOmsjdWVX1KHAb8GvAGUmWtkUrgH1teh9wNkBb/kLg4eH6EescrS5JmpBx3p01l+SMNv0C4DeBexmEyVvasA3AzW16e5unLf9yVVWrX9Lu3joXWAXcAdwJrGp3e53G4OL79nHtjyTp6ZY+85BuLwW2tLuoTgFuqqovJtkDbEvyQeBu4Po2/nrgxiTzwEEGoUBV7U5yE7AHOARcXlVPASR5D7ADWAJsrqrdY9wfSdIRxhYiVfVN4NUL1B9gcH3kyPpPgLceZVtXA1cvUL8FuOWEm5UkdfGJdUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt5FCJMmto9QkSYvLMV8Fn+T5wM8Ay5KcCaQtOp2j/J65JGnxeKbfE/kD4H3Ay4C7+L8QeRz4+zH2JUmaAccMkar6KPDRJH9YVR+bUE+SpBkx0i8bVtXHkvw6sHJ4naraOqa+JEkzYKQQSXIj8AvAN4CnWrkAQ0SSFrFRf2N9DbC6qmqczUiSZsuoz4l8C3jJOBuRJM2eUY9ElgF7ktwBPHG4WFVvGktXkqSZMGqI/MU4m5AkzaZR7876l3E3IkmaPaPenfVDBndjAZwGnAr8d1WdPq7GJEknv1GPRH7u8HSSAOuBteNqSpI0G477Lb418E/AhWPoR5I0Q0Y9nfXmodlTGDw38pOxdCRJmhmj3p31O0PTh4DvMDilJUlaxEa9JvLOcTciSZo9o/4o1Yok/5hkf/t8PsmKcTcnSTq5jXph/dPAdga/K/Iy4J9bTZK0iI0aInNV9emqOtQ+NwBzY+xLkjQDRg2Rh5O8PcmS9nk78PA4G5MknfxGDZHfB94GfA94CHgL8I4x9SRJmhGj3uJ7FbChqh4BSPIi4CMMwkWStEiNeiTyK4cDBKCqDgKvHk9LkqRZMWqInJLkzMMz7UjkmEcxSc5OcluSPUl2J3nv4XWT7Exyf/t7ZqsnybVJ5pN8M8lrhra1oY2/P8mGofprk9zT1rm2vddLkjQho4bI3wBfS/KBJB8A/g34q2dY5xDwR1W1msHLGi9Pshq4Ari1qlYBt7Z5gIuAVe2zCfgk/DSwrgReB5wHXDkUaJ8E3jW03roR90eS9CwYKUSqaivwZuD77fPmqrrxGdZ5qKr+vU3/ELgXWM7gdSlb2rAtwMVtej2wtb3g8XbgjCQvZfCix51VdbCdUtsJrGvLTq+q29tvv28d2pYkaQJGvbBOVe0B9vR8SZKVDK6hfB04q6oeaou+B5zVppcDDw6ttrfVjlXfu0B9oe/fxODohnPOOadnFyRJCzjuV8EfryQ/C3weeF9VPT68rB1B1IIrPouq6rqqWlNVa+bmfEZSkp4tYw2RJKcyCJB/qKovtPL326ko2t/9rb4POHto9RWtdqz6igXqkqQJGVuItDulrgfuraq/HVq0HTh8h9UG4Oah+mXtLq21wGPttNcO4IIkZ7YL6hcAO9qyx5Osbd912dC2JEkTMPI1kQ6vB34PuCfJN1rtz4APATcl2Qh8l8GT8AC3AG8E5oEfA++EwTMp7Y6wO9u4q9pzKgDvBm4AXgB8qX0kSRMythCpqn8FjvbcxvkLjC/g8qNsazOweYH6LuCVJ9CmJOkEjP3CuiTpucsQkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1G1sIZJkc5L9Sb41VHtRkp1J7m9/z2z1JLk2yXySbyZ5zdA6G9r4+5NsGKq/Nsk9bZ1rk2Rc+yJJWtg4j0RuANYdUbsCuLWqVgG3tnmAi4BV7bMJ+CQMQge4EngdcB5w5eHgaWPeNbTekd8lSRqzsYVIVX0VOHhEeT2wpU1vAS4eqm+tgduBM5K8FLgQ2FlVB6vqEWAnsK4tO72qbq+qArYObUuSNCGTviZyVlU91Ka/B5zVppcDDw6N29tqx6rvXaAuSZqgqV1Yb0cQNYnvSrIpya4kuw4cODCJr5SkRWHSIfL9diqK9nd/q+8Dzh4at6LVjlVfsUB9QVV1XVWtqao1c3NzJ7wTkqSBSYfIduDwHVYbgJuH6pe1u7TWAo+10147gAuSnNkuqF8A7GjLHk+ytt2VddnQtiRJE7J0XBtO8hngN4BlSfYyuMvqQ8BNSTYC3wXe1obfArwRmAd+DLwToKoOJvkAcGcbd1VVHb5Y/24Gd4C9APhS+0iSJmhsIVJVlx5l0fkLjC3g8qNsZzOweYH6LuCVJ9KjJOnE+MS6JKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkbkun3cCsee0fb512CzoJ3fXXl027BWkqPBKRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHWb+RBJsi7JfUnmk1wx7X4kaTGZ6RBJsgT4OHARsBq4NMnq6XYlSYvHTIcIcB4wX1UPVNWTwDZg/ZR7kqRFY9Z/lGo58ODQ/F7gdUcOSrIJ2NRmf5Tkvgn0thgsA34w7SZOBvnIhmm3oKfz//OwK3OiW/j5oy2Y9RAZSVVdB1w37T6ea5Lsqqo10+5DWoj/n5Mx66ez9gFnD82vaDVJ0gTMeojcCaxKcm6S04BLgO1T7kmSFo2ZPp1VVYeSvAfYASwBNlfV7im3tZh4ilAnM/8/JyBVNe0eJEkzatZPZ0mSpsgQkSR1M0TUxdfN6GSVZHOS/Um+Ne1eFgNDRMfN183oJHcDsG7aTSwWhoh6+LoZnbSq6qvAwWn3sVgYIuqx0Otmlk+pF0lTZIhIkroZIurh62YkAYaI+vi6GUmAIaIOVXUIOPy6mXuBm3zdjE4WST4DfA34xSR7k2ycdk/PZb72RJLUzSMRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEpClKclWS9w3NX53kvdPsSToePmwoTVGSlcAXquo1SU4B7gfOq6qHp9qYNKKl025AWsyq6jtJHk7yauAs4G4DRLPEEJGm71PAO4CXAJun24p0fDydJU1ZexPyPcCpwKqqemrKLUkj80hEmrKqejLJbcCjBohmjSEiTVm7oL4WeOu0e5GOl7f4SlOUZDUwD9xaVfdPux/peHlNRJLUzSMRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt/8F3G3SUyMdbocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x = \"y\", data = df_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uaPJqMGN6Hw"
   },
   "source": [
    "We do not have much of negative comments. We will use data augmentation to create more data our methodology will be we take sentences having 5 star rating and then select the reviews of length in the range of 20 to 30 words.  \n",
    "\n",
    "After havving these positive reviews we will use Antonym Augmentation to generate negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NRr67JylN6Hw"
   },
   "outputs": [],
   "source": [
    "df_temp2 = df_temp[(df_temp['ratings'] == '5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5_O_IuKN6Hw",
    "outputId": "bd04521d-9c3d-48f9-d129-1951dcdd0dbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4803"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = list(df_temp2[(df_temp2['review'].str.len() > 100) & (df_temp2['review'].str.len() < 350)]['review'])\n",
    "len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3C7kT5uN6Hw",
    "outputId": "b0ab51e0-1cda-4f2c-b15a-e15d501958ca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.7/dist-packages (1.1.11)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.21.6)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2022.2.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2022.6.15)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "53m-IGoiN6Hw"
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71Vl3uatN6Hx"
   },
   "source": [
    "We used Python‚Äôs NLPAug to do the data augmentation task. First, we choose positive reviews of 100-350 character lengths which were 4803. Just have a look at few of the reviews in below shown image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y2yxBdgN6Hx",
    "outputId": "33a31b4c-f666-409e-f636-6b7a5dc17f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"An amazing smartphone for the price though i didn't like the colors compared to a realme phone in the same price range. It's a reall good second smartphone if you already have a primary device.\",\n",
       " \"Nice product according to its budget. But it's hard to play high Graphics games like pubg on 3GB RAM. It lags even when you play at Smooth Graphics settings. If this is for gaming (High graphics game) purpose, then don't go for 3GB or 2 GB RAM and the rest it works very well.\",\n",
       " 'I gave this phone to my wife as a gift and she loved it so much that she gets great performance and photos of games',\n",
       " 'Every thing is great about the phone but a micro USB connector with a 5000 mah battery kind of suck a type c connector would have been better',\n",
       " 'Very good handset at this price. Nice and great performance. Battery backup is also trustworthy. There is no issue till date after using for a period of 5days. Overall u can buy this phone without hesitation',\n",
       " 'I am happy with your productus policy of discount  and best service flipcart.we wish day by day growth. And give more and more service from your sight.           ThanksHasmukh patel.Ahmedabad. Gujarat',\n",
       " \"Mobile phone is Good..  good camera clarity.. I have one problem with the phone, when I do video calling there is lot of noise, so I can't hear properly, lot of sound disturbance, but when I do voice call.. the sound is clear..\",\n",
       " \"An amazing smartphone for the price though i didn't like the colors compared to a realme phone in the same price range. It's a reall good second smartphone if you already have a primary device.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive[41:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ww-nwfo5N6Hx"
   },
   "outputs": [],
   "source": [
    "aug = naw.AntonymAug(name='Antonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', stopwords=en_stopwords, tokenizer=None, \n",
    "                     reverse_tokenizer=None, stopwords_regex=None, verbose=0)\n",
    " \n",
    "aug_negative = aug.augment(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obrmStrEN6Hx",
    "outputId": "d3adba9c-591a-41a7-c790-7112c10de6fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4803"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uhY8Z2sN6Hx"
   },
   "source": [
    "After having 4803 positive reviews we applied word level augmentation specifically Antonym Augmentation which changes the context of the word (make them opposite of that). \n",
    "Using this we got around 4803 negative reviews as well hence the balanced data. Have a look at the negative version of the above positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0JSQ9zfN6Hx",
    "outputId": "07993b7c-3c72-4425-e643-ab71b9cee651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"An amazing smartphone for the price though i didn ' t like the colors compared to a realme phone in the same price range. It ' s a reall evil second smartphone if you already have a secondary device.\",\n",
       " \"Nice product according to its budget. But it ' s hard to play low Graphics games like pubg on 3GB RAM. It lags even when you play at Smooth Graphics settings. If this is for gaming (Low graphics game) purpose, then don ' t stay in place for 3GB or 2 GB RAM and the rest it idle very badly.\",\n",
       " 'I starve this phone to my wife as a gift and she hate it so little that she end great performance and photos of games',\n",
       " 'Every thing is great about the phone but a micro USB connector with a 5000 mah battery kind of suck a type c connector would have been ill',\n",
       " 'Very evil handset at this price. Nice and great performance. Battery backup is also untrustworthy. There is no issue till date after using for a period of 5days. Overall u can sell this phone without hesitation',\n",
       " 'I am unhappy with your productus policy of discount and evil service flipcart. we wish day by day growth. And starve more and more service from your sight. ThanksHasmukh patel. Ahmedabad. Gujarat',\n",
       " \"Mobile phone is Bad. . evil camera clarity. . I have one problem with the phone, when I do video calling there is lot of noise, so I can ' t hear improperly, lot of unsound disturbance, but when I do voice call. . the sound is unclear..\",\n",
       " \"An amazing smartphone for the price though i didn ' t like the colors compared to a realme phone in the same price range. It ' s a reall evil second smartphone if you already have a secondary device.\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_negative[41:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "7kyjTegGN6Hx"
   },
   "outputs": [],
   "source": [
    "df_negative = pd.DataFrame({\"review\" : aug_negative, 'y' : [0]*len(aug_negative)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "YnmRB4v3N6Hx"
   },
   "outputs": [],
   "source": [
    "df_positive = pd.DataFrame({\"review\" : positive, 'y' : [1]*len(positive)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_0G9fKGN6Hx"
   },
   "source": [
    "Concatination both negative and positive sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KFKq7ODvN6Hx"
   },
   "outputs": [],
   "source": [
    "df_temp = pd.concat([df_negative, df_positive]).sample(frac = 1, random_state = 11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feViToCWN6Hx",
    "outputId": "acb6e16c-3641-4fe5-d4a4-fc22b00e42e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9606 entries, 0 to 9605\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  9606 non-null   object\n",
      " 1   y       9606 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 150.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1IkSujtrN6Hx",
    "outputId": "245778b9-1111-483f-deec-20dc2f704dc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-57985ccc-e417-48be-a013-7871ca9db535\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57985ccc-e417-48be-a013-7871ca9db535')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-57985ccc-e417-48be-a013-7871ca9db535 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-57985ccc-e417-48be-a013-7871ca9db535');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y\n",
       "0  great phone in budget. .. pubg performance was...  0\n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0\n",
       "2  Evil smooth phone. . and back camera quality i...  0\n",
       "3  Thise is very nice mobile ...I like it very mu...  1\n",
       "4  I m meagerly fall short of üëç All section r sup...  0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "qF2pAsitN6Hx"
   },
   "outputs": [],
   "source": [
    "df = df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7xb3GRrN6Hx"
   },
   "source": [
    "Applying Text cleaning and preprocessing on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "jpK-ivz2N6Hx"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \n",
    "    text = remove_url(text) \n",
    "    text = uni.normalize('NFKD', text)\n",
    "    text = handle_emoji(text)\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = word_tokenizer(text)\n",
    "    # text = stemming(text)\n",
    "    text = lemmatization(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFdCkUmhN6Hx",
    "outputId": "de883246-d1c2-4883-b074-90fd23973e1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [02:31<00:00, 63.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df['clean_review'] = df['review'].progress_map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bU1yV8-5N6Hx",
    "outputId": "3cf76ff6-33c1-4dda-dd80-ec9da02237eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-25411a45-b026-44ae-a0eb-e8b50d8878f6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "      <td>great phone budget pubg performance rough came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>good smartphone mi range stop r confused samsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "      <td>evil smooth phone back camera quality bad rear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>thise nice mobile I like much delivery also fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>I meagerly fall short thumb section r superb d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25411a45-b026-44ae-a0eb-e8b50d8878f6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-25411a45-b026-44ae-a0eb-e8b50d8878f6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-25411a45-b026-44ae-a0eb-e8b50d8878f6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y  \\\n",
       "0  great phone in budget. .. pubg performance was...  0   \n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0   \n",
       "2  Evil smooth phone. . and back camera quality i...  0   \n",
       "3  Thise is very nice mobile ...I like it very mu...  1   \n",
       "4  I m meagerly fall short of üëç All section r sup...  0   \n",
       "\n",
       "                                        clean_review  \n",
       "0  great phone budget pubg performance rough came...  \n",
       "1  good smartphone mi range stop r confused samsu...  \n",
       "2  evil smooth phone back camera quality bad rear...  \n",
       "3  thise nice mobile I like much delivery also fa...  \n",
       "4  I meagerly fall short thumb section r superb d...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "LfpzlKouN6Hx"
   },
   "outputs": [],
   "source": [
    "reviews = df.clean_review.values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5WQZGB2N6Hx"
   },
   "source": [
    "Prepare data for LDA Analysis\n",
    "Next, let‚Äôs work to transform the textual data in a format that will serve as an input for training LDA model. We start by tokenizing the text and removing stopwords. Next, we convert the tokenized object into a corpus and dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWiyflfxN6Hx",
    "outputId": "f1eff61e-c574-4edb-bf14-c664eb6ccdaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:00<00:00, 213655.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df['clean_review2'] = df['clean_review'].progress_map(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dbgxeTBXN6Hx",
    "outputId": "adbaffbc-b36c-4cc9-a36d-3f4ecf7a5b83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b9d8a71a-cc91-46f1-b4dc-4a2584f6b80d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "      <td>great phone budget pubg performance rough came...</td>\n",
       "      <td>[great, phone, budget, pubg, performance, roug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>good smartphone mi range stop r confused samsu...</td>\n",
       "      <td>[good, smartphone, mi, range, stop, r, confuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "      <td>evil smooth phone back camera quality bad rear...</td>\n",
       "      <td>[evil, smooth, phone, back, camera, quality, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>thise nice mobile I like much delivery also fa...</td>\n",
       "      <td>[thise, nice, mobile, i, like, much, delivery,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>I meagerly fall short thumb section r superb d...</td>\n",
       "      <td>[i, meagerly, fall, short, thumb, section, r, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9d8a71a-cc91-46f1-b4dc-4a2584f6b80d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b9d8a71a-cc91-46f1-b4dc-4a2584f6b80d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b9d8a71a-cc91-46f1-b4dc-4a2584f6b80d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y  \\\n",
       "0  great phone in budget. .. pubg performance was...  0   \n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0   \n",
       "2  Evil smooth phone. . and back camera quality i...  0   \n",
       "3  Thise is very nice mobile ...I like it very mu...  1   \n",
       "4  I m meagerly fall short of üëç All section r sup...  0   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  great phone budget pubg performance rough came...   \n",
       "1  good smartphone mi range stop r confused samsu...   \n",
       "2  evil smooth phone back camera quality bad rear...   \n",
       "3  thise nice mobile I like much delivery also fa...   \n",
       "4  I meagerly fall short thumb section r superb d...   \n",
       "\n",
       "                                       clean_review2  \n",
       "0  [great, phone, budget, pubg, performance, roug...  \n",
       "1  [good, smartphone, mi, range, stop, r, confuse...  \n",
       "2  [evil, smooth, phone, back, camera, quality, b...  \n",
       "3  [thise, nice, mobile, i, like, much, delivery,...  \n",
       "4  [i, meagerly, fall, short, thumb, section, r, ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeKgYV1SN6Hy"
   },
   "source": [
    "Now as our dataset is unlabeled so we need an algorithm that can get labels to us. We will use the following algorithm (LDA) to do so. We will use Topic Modeling Technique to find aspects from the reviews.\n",
    "\n",
    "In general, topic modelling refers to a set of unsupervised statistical learning methods for detecting latent topics in a large number of text texts. Latent Dirichlet allocation (LDA), latent semantic analysis (LSA), and probabilistic latent semantic analysis are three prominent topic modelling algorithms (PLSA). LDA is the most widely employed approach in practise. And we will too gonna use LDA for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6t8FRohN6Hy"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">5. Latent Dirichlet Allocation (LDA) </h1><a id = \"5\" ></a>\n",
    "\n",
    "\n",
    "**What does LDA do? Let‚Äôs start with a toy corpus.**\n",
    "\n",
    "Consider the following collection of documents, D1 to D5, and each document consists of a one sentence:\n",
    "\n",
    "‚Ä¢ D1: I like these mobile phones.\n",
    "‚Ä¢ D2: Battery backup for this phone is great and camera quality is an add on feature.\n",
    "‚Ä¢ D3: Look at the front camera I guess it is better than the rear camera.\n",
    "‚Ä¢ D4: Processing Speed of this phone is great.\n",
    "‚Ä¢ D5: I Like the battery most in this phone but I am not satisfied with the service of this company.\n",
    "\n",
    "Learning a topic model on this collection using LDA may produce an output like this:\n",
    "\n",
    "‚Ä¢ Topic A: 30% battery, 15% camera, 10% Processor, 10% Service.\n",
    "‚Ä¢ Topic B: 20% Rear Camera, 20% Front Camera, 20% Service, 20% Processor\n",
    "‚Ä¢ Document 1 and 2: 100% Topic A\n",
    "‚Ä¢ Document 3 and 4: 100% Topic B\n",
    "‚Ä¢ Document 5: 60% Topic A, 40% Topic B\n",
    "\n",
    "Topics are just a collection of keywords with a probability distribution, while documents are collections of topics with the same probability distribution. A topic model just provides a list of keywords for each topic. What is the situation?Human perception of what an issue symbolises and what it should be labelled is common in the context of an LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErKMjfJ9N6Hy",
    "outputId": "822200db-0ea3-4f75-92d7-c4b7740b4f47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9606"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words = df['clean_review2'].values.tolist()\n",
    "len(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScfKVGMfN6Hy"
   },
   "source": [
    "You could refer this blog post to understand LDA more nicely.\n",
    "\n",
    "[Topic Modeling in Python: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qdjMqBYN6Hy",
    "outputId": "f725646a-f9cb-48dc-8bcd-e0e6b0d3dc3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 3), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlKx7zuxN6Hy",
    "outputId": "4d1700ba-2c61-4ddf-a28a-fbc246c982eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.040*\"camera\" + 0.026*\"phone\" + 0.025*\"good\" + 0.025*\"awesome\" + '\n",
      "  '0.019*\"quality\" + 0.017*\"flipkart\" + 0.016*\"battery\" + 0.014*\"thank\" + '\n",
      "  '0.014*\"price\" + 0.014*\"fast\"'),\n",
      " (1,\n",
      "  '0.032*\"i\" + 0.024*\"good\" + 0.023*\"flipkart\" + 0.023*\"product\" + '\n",
      "  '0.021*\"great\" + 0.020*\"mobile\" + 0.016*\"really\" + 0.016*\"phone\" + '\n",
      "  '0.015*\"also\" + 0.012*\"price\"'),\n",
      " (2,\n",
      "  '0.043*\"phone\" + 0.042*\"good\" + 0.032*\"i\" + 0.028*\"camera\" + 0.022*\"battery\" '\n",
      "  '+ 0.016*\"display\" + 0.015*\"quality\" + 0.012*\"bad\" + 0.012*\"face\" + '\n",
      "  '0.012*\"also\"'),\n",
      " (3,\n",
      "  '0.047*\"good\" + 0.042*\"phone\" + 0.035*\"i\" + 0.031*\"camera\" + 0.018*\"battery\" '\n",
      "  '+ 0.014*\"quality\" + 0.013*\"evil\" + 0.013*\"performance\" + 0.013*\"use\" + '\n",
      "  '0.012*\"bad\"'),\n",
      " (4,\n",
      "  '0.054*\"good\" + 0.040*\"phone\" + 0.032*\"camera\" + 0.025*\"battery\" + '\n",
      "  '0.020*\"evil\" + 0.017*\"ok\" + 0.016*\"hand\" + 0.015*\"price\" + 0.015*\"great\" + '\n",
      "  '0.014*\"performance\"'),\n",
      " (5,\n",
      "  '0.045*\"i\" + 0.036*\"phone\" + 0.023*\"flipkart\" + 0.021*\"product\" + '\n",
      "  '0.020*\"delivery\" + 0.020*\"bad\" + 0.019*\"camera\" + 0.018*\"thank\" + '\n",
      "  '0.017*\"price\" + 0.016*\"mobile\"'),\n",
      " (6,\n",
      "  '0.037*\"i\" + 0.024*\"camera\" + 0.021*\"battery\" + 0.019*\"good\" + '\n",
      "  '0.018*\"mobile\" + 0.016*\"product\" + 0.015*\"phone\" + 0.013*\"thank\" + '\n",
      "  '0.012*\"nice\" + 0.012*\"performance\"'),\n",
      " (7,\n",
      "  '0.073*\"face\" + 0.066*\"smile\" + 0.039*\"heart\" + 0.032*\"red\" + 0.021*\"i\" + '\n",
      "  '0.020*\"product\" + 0.019*\"hearteyes\" + 0.018*\"camera\" + 0.017*\"good\" + '\n",
      "  '0.017*\"phone\"'),\n",
      " (8,\n",
      "  '0.050*\"phone\" + 0.045*\"bad\" + 0.035*\"camera\" + 0.026*\"good\" + 0.025*\"evil\" '\n",
      "  '+ 0.022*\"price\" + 0.020*\"quality\" + 0.020*\"battery\" + 0.017*\"i\" + '\n",
      "  '0.014*\"performance\"'),\n",
      " (9,\n",
      "  '0.058*\"phone\" + 0.049*\"i\" + 0.026*\"good\" + 0.020*\"mobile\" + 0.018*\"camera\" '\n",
      "  '+ 0.015*\"battery\" + 0.014*\"awesome\" + 0.014*\"price\" + 0.013*\"use\" + '\n",
      "  '0.012*\"redmi\"')]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=id2word,\n",
    "                     num_topics=num_topics, iterations=400)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFU3rGVeN6Hy"
   },
   "source": [
    "As we don't have labeled data so we need to make few assumptions regarding choosing of aspect from the comment. From above analysis using LDA we inerpret that below listed aspect are few important one which were mentioned in most of the comments. \n",
    "- Phone\n",
    "- Camera\n",
    "- Battery\n",
    "- Delivery\n",
    "- Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehdaeTinN6Hy"
   },
   "source": [
    "We gonna create a similarity matrix now using python's gensim. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yha17AXsN6Hy",
    "outputId": "e1cc124d-9612-469e-9f9b-df76aa763d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 480 ms, total: 16.3 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.fasttext import FastText\n",
    "fasttext_model = FastText(data_words, vector_size = 100, window=5, min_count=5, workers=4,sg=1)\n",
    "# fasttext_model = FastText.load_fasttext_format(\"../input/fast100/cc.en.100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgfR5epUhvJy",
    "outputId": "452e33cc-1e69-49bc-938d-3d7f5f8da0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "-QUToxJLN6Hy"
   },
   "outputs": [],
   "source": [
    "fasttext_model.save(\"FastText-Model-For-ABSA.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9s485ARN6Hy",
    "outputId": "e51356fd-5ae7-434e-ff19-781716ade418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298448"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.n_similarity(\"I really like the camera of this phone\", \"battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOCMx4WIN6Hy",
    "outputId": "4c613770-4e06-4e73-b6af-1ed9fa1d1c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88993496"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.n_similarity(\"I really like the camera of this phone\", \"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Dx3mPScCN6Hy"
   },
   "outputs": [],
   "source": [
    "aspects = [\"phone\", \"camera\", \"battery\", \"delivery\", \"processor\"]\n",
    "\n",
    "def get_similarity(text, aspect):\n",
    "    try:\n",
    "        text = \" \".join(text)\n",
    "        return fasttext_model.wv.n_similarity(text, aspect)\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hF1DW4tgN6Hy",
    "outputId": "9c98efc8-9bce-41f3-b133-9f786b9815ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:18<00:00, 505.63it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:23<00:00, 412.12it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:10<00:00, 917.10it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:08<00:00, 1080.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9606/9606 [00:09<00:00, 1043.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "for aspect in aspects:\n",
    "    df[aspect] = df['clean_review2'].progress_map(lambda text: get_similarity(text, aspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3i51xZRdN6Hy",
    "outputId": "372c9b2d-aa09-4047-8c0d-7e8c5f2ca258"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-881d8052-b4a3-4158-b0fe-f53240c38ea8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review2</th>\n",
       "      <th>phone</th>\n",
       "      <th>camera</th>\n",
       "      <th>battery</th>\n",
       "      <th>delivery</th>\n",
       "      <th>processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "      <td>great phone budget pubg performance rough came...</td>\n",
       "      <td>[great, phone, budget, pubg, performance, roug...</td>\n",
       "      <td>0.900222</td>\n",
       "      <td>0.877657</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.891804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>good smartphone mi range stop r confused samsu...</td>\n",
       "      <td>[good, smartphone, mi, range, stop, r, confuse...</td>\n",
       "      <td>0.892999</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.926519</td>\n",
       "      <td>0.940637</td>\n",
       "      <td>0.853622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "      <td>evil smooth phone back camera quality bad rear...</td>\n",
       "      <td>[evil, smooth, phone, back, camera, quality, b...</td>\n",
       "      <td>0.878147</td>\n",
       "      <td>0.911873</td>\n",
       "      <td>0.931737</td>\n",
       "      <td>0.928768</td>\n",
       "      <td>0.910587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>thise nice mobile I like much delivery also fa...</td>\n",
       "      <td>[thise, nice, mobile, i, like, much, delivery,...</td>\n",
       "      <td>0.875378</td>\n",
       "      <td>0.843419</td>\n",
       "      <td>0.886922</td>\n",
       "      <td>0.954610</td>\n",
       "      <td>0.836108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>I meagerly fall short thumb section r superb d...</td>\n",
       "      <td>[i, meagerly, fall, short, thumb, section, r, ...</td>\n",
       "      <td>0.865953</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.951442</td>\n",
       "      <td>0.959166</td>\n",
       "      <td>0.888991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-881d8052-b4a3-4158-b0fe-f53240c38ea8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-881d8052-b4a3-4158-b0fe-f53240c38ea8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-881d8052-b4a3-4158-b0fe-f53240c38ea8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y  \\\n",
       "0  great phone in budget. .. pubg performance was...  0   \n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0   \n",
       "2  Evil smooth phone. . and back camera quality i...  0   \n",
       "3  Thise is very nice mobile ...I like it very mu...  1   \n",
       "4  I m meagerly fall short of üëç All section r sup...  0   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  great phone budget pubg performance rough came...   \n",
       "1  good smartphone mi range stop r confused samsu...   \n",
       "2  evil smooth phone back camera quality bad rear...   \n",
       "3  thise nice mobile I like much delivery also fa...   \n",
       "4  I meagerly fall short thumb section r superb d...   \n",
       "\n",
       "                                       clean_review2     phone    camera  \\\n",
       "0  [great, phone, budget, pubg, performance, roug...  0.900222  0.877657   \n",
       "1  [good, smartphone, mi, range, stop, r, confuse...  0.892999  0.831100   \n",
       "2  [evil, smooth, phone, back, camera, quality, b...  0.878147  0.911873   \n",
       "3  [thise, nice, mobile, i, like, much, delivery,...  0.875378  0.843419   \n",
       "4  [i, meagerly, fall, short, thumb, section, r, ...  0.865953  0.864542   \n",
       "\n",
       "    battery  delivery  processor  \n",
       "0  0.938197  0.910938   0.891804  \n",
       "1  0.926519  0.940637   0.853622  \n",
       "2  0.931737  0.928768   0.910587  \n",
       "3  0.886922  0.954610   0.836108  \n",
       "4  0.951442  0.959166   0.888991  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "EW_Hzni4N6Hy"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Clean_Flipkart_Product.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2Hqk8vKN6Hy"
   },
   "source": [
    "As of now we are done of choosing the aspects for each respective review. Now our next step will be to create an pytorch based model which can predict aspect based sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynx-1rOiN6Hy"
   },
   "source": [
    "--------------------------------------------\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSuxYeW_N6Hz"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P23stOhFN6Hz"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">6. Model </h1><a id = \"6\" ></a>\n",
    "\n",
    "We are done with aspect identification next we will create a model to predict sentiments on the basis of these aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Aej0y8W_N6Hz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN4BF9hgN6Hz"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 6.1 Configurations </h2><a id = \"6.1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "J3_qHMOgN6Hz"
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "    IMG_SIZE = (224,224)\n",
    "    DEVICE = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    FOLDS = 5\n",
    "    SHUFFLE = True\n",
    "    BATCH_SIZE = 32\n",
    "    LR = 0.01\n",
    "    EPOCHS = 30\n",
    "    EMB_DIM = 100\n",
    "    MAX_LEN = 20\n",
    "    MODEL_PATH = \"./Models/MyModel.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t1H1Zgc5N6Hz",
    "outputId": "c2cd1148-12cd-43c4-da7d-7e9c06a82800"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-228d41a5-9a23-4f77-a5d8-58c31c9adcbe\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review2</th>\n",
       "      <th>phone</th>\n",
       "      <th>camera</th>\n",
       "      <th>battery</th>\n",
       "      <th>delivery</th>\n",
       "      <th>processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "      <td>great phone budget pubg performance rough came...</td>\n",
       "      <td>[great, phone, budget, pubg, performance, roug...</td>\n",
       "      <td>0.900222</td>\n",
       "      <td>0.877657</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.891804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>good smartphone mi range stop r confused samsu...</td>\n",
       "      <td>[good, smartphone, mi, range, stop, r, confuse...</td>\n",
       "      <td>0.892999</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.926519</td>\n",
       "      <td>0.940637</td>\n",
       "      <td>0.853622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "      <td>evil smooth phone back camera quality bad rear...</td>\n",
       "      <td>[evil, smooth, phone, back, camera, quality, b...</td>\n",
       "      <td>0.878147</td>\n",
       "      <td>0.911873</td>\n",
       "      <td>0.931737</td>\n",
       "      <td>0.928768</td>\n",
       "      <td>0.910587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>thise nice mobile I like much delivery also fa...</td>\n",
       "      <td>[thise, nice, mobile, i, like, much, delivery,...</td>\n",
       "      <td>0.875378</td>\n",
       "      <td>0.843419</td>\n",
       "      <td>0.886922</td>\n",
       "      <td>0.954610</td>\n",
       "      <td>0.836108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>I meagerly fall short thumb section r superb d...</td>\n",
       "      <td>[i, meagerly, fall, short, thumb, section, r, ...</td>\n",
       "      <td>0.865953</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.951442</td>\n",
       "      <td>0.959166</td>\n",
       "      <td>0.888991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-228d41a5-9a23-4f77-a5d8-58c31c9adcbe')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-228d41a5-9a23-4f77-a5d8-58c31c9adcbe button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-228d41a5-9a23-4f77-a5d8-58c31c9adcbe');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y  \\\n",
       "0  great phone in budget. .. pubg performance was...  0   \n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0   \n",
       "2  Evil smooth phone. . and back camera quality i...  0   \n",
       "3  Thise is very nice mobile ...I like it very mu...  1   \n",
       "4  I m meagerly fall short of üëç All section r sup...  0   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  great phone budget pubg performance rough came...   \n",
       "1  good smartphone mi range stop r confused samsu...   \n",
       "2  evil smooth phone back camera quality bad rear...   \n",
       "3  thise nice mobile I like much delivery also fa...   \n",
       "4  I meagerly fall short thumb section r superb d...   \n",
       "\n",
       "                                       clean_review2     phone    camera  \\\n",
       "0  [great, phone, budget, pubg, performance, roug...  0.900222  0.877657   \n",
       "1  [good, smartphone, mi, range, stop, r, confuse...  0.892999  0.831100   \n",
       "2  [evil, smooth, phone, back, camera, quality, b...  0.878147  0.911873   \n",
       "3  [thise, nice, mobile, i, like, much, delivery,...  0.875378  0.843419   \n",
       "4  [i, meagerly, fall, short, thumb, section, r, ...  0.865953  0.864542   \n",
       "\n",
       "    battery  delivery  processor  \n",
       "0  0.938197  0.910938   0.891804  \n",
       "1  0.926519  0.940637   0.853622  \n",
       "2  0.931737  0.928768   0.910587  \n",
       "3  0.886922  0.954610   0.836108  \n",
       "4  0.951442  0.959166   0.888991  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../input/mimobilereviews/Clean_Flipkart_Product.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV-QZ8nFN6Hz"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-OcH8nlfN6Hz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrZpKdiWN6Hz"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 6.2 Dataset Generator </h2><a id = \"6.2\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M238pRBtN6Hz"
   },
   "source": [
    "<h3  style=\"text-align: center\" class=\"list-group-item list-group-item-warning\"> 6.2.1 Creation of the Vocabulary </h3><a id = \"6.2.1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "QpJ_oDiqN6Hz"
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "  \n",
    "    '''\n",
    "    __init__ method is called by default as soon as an object of this class is initiated\n",
    "    we use this method to initiate our vocab dictionaries\n",
    "    '''\n",
    "    def __init__(self, freq_threshold, max_size):\n",
    "        '''\n",
    "        freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "        max_size : max source vocab size. Eg. if set to 10,000, we pick the top 10,000 most frequent words and discard others\n",
    "        '''\n",
    "        #initiate the index to token dict\n",
    "        ## <PAD> -> padding, used for padding the shorter sentences in a batch to match the length of longest sentence in the batch\n",
    "        ## <SOS> -> start token, added in front of each sentence to signify the start of sentence\n",
    "        ## <EOS> -> End of sentence token, added to the end of each sentence to signify the end of sentence\n",
    "        ## <UNK> -> words which are not found in the vocab are replace by this token\n",
    "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
    "        #initiate the token to index dict\n",
    "        self.stoi = {k:j for j,k in self.itos.items()} \n",
    "        \n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    '''\n",
    "    __len__ is used by dataloader later to create batches\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    '''\n",
    "    a simple tokenizer to split on space and converts the sentence to list of words\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower().strip() for tok in text.split(' ')]\n",
    "    \n",
    "    '''\n",
    "    build the vocab: create a dictionary mapping of index to string (itos) and string to index (stoi)\n",
    "    output ex. for stoi -> {'the':5, 'a':6, 'an':7}\n",
    "    '''\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        #calculate the frequencies of each word first to remove the words with freq < freq_threshold\n",
    "        frequencies = {}  #init the freq dict\n",
    "        idx = 4 #index from which we want our dict to start. We already used 4 indexes for pad, start, end, unk\n",
    "        \n",
    "        #calculate freq of words\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer(sentence):\n",
    "                if word not in frequencies.keys():\n",
    "                    frequencies[word]=1\n",
    "                else:\n",
    "                    frequencies[word]+=1\n",
    "                    \n",
    "                    \n",
    "        #limit vocab by removing low freq words\n",
    "        frequencies = {k:v for k,v in frequencies.items() if v>self.freq_threshold} \n",
    "        \n",
    "        #limit vocab to the max_size specified\n",
    "        frequencies = dict(sorted(frequencies.items(), key = lambda x: -x[1])[:self.max_size-idx]) # idx =4 for pad, start, end , unk\n",
    "            \n",
    "        #create vocab\n",
    "        for word in frequencies.keys():\n",
    "            self.stoi[word] = idx\n",
    "            self.itos[idx] = word\n",
    "            idx+=1\n",
    "            \n",
    "     \n",
    "    '''\n",
    "    convert the list of words to a list of corresponding indexes\n",
    "    '''    \n",
    "    def numericalize(self, text):\n",
    "        #tokenize text\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        numericalized_text = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.stoi.keys():\n",
    "                numericalized_text.append(self.stoi[token])\n",
    "            else: #out-of-vocab words are represented by UNK token index\n",
    "                numericalized_text.append(self.stoi['<UNK>'])\n",
    "                \n",
    "        return numericalized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "vwJJU5WZN6Hz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    Initiating Variables\n",
    "    df: the training dataframe\n",
    "    source_column : the name of source text column in the dataframe\n",
    "    transform : If we want to add any augmentation\n",
    "    freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "    source_vocab_max_size : max source vocab size\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, df, source_column,freq_threshold = 3,\n",
    "                source_vocab_max_size = 10000 , transform=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        #get source and target texts\n",
    "        self.source_texts = self.df[source_column]\n",
    "        \n",
    "        \n",
    "        ##VOCAB class has been created above\n",
    "        #Initialize source vocab object and build vocabulary\n",
    "        self.source_vocab = Vocabulary(freq_threshold, source_vocab_max_size)\n",
    "        self.source_vocab.build_vocabulary(self.source_texts.tolist())\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    '''\n",
    "    __getitem__ runs on 1 example at a time. Here, we get an example at index and return its numericalize source and\n",
    "    target values using the vocabulary objects we created in __init__\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.source_texts[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "            \n",
    "        #numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
    "        numerialized_source = [self.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numerialized_source += self.source_vocab.numericalize(source_text)\n",
    "        numerialized_source.append(self.source_vocab.stoi[\"<EOS>\"])\n",
    "        \n",
    "        #convert the list to tensor and return\n",
    "        return torch.tensor(numerialized_source), torch.tensor(self.df.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xJ1c9htpN6Hz",
    "outputId": "cf3412d7-aaab-4285-c812-3703778aa94e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9348e003-ceb9-49b4-8e87-85d199e1649b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review2</th>\n",
       "      <th>phone</th>\n",
       "      <th>camera</th>\n",
       "      <th>battery</th>\n",
       "      <th>delivery</th>\n",
       "      <th>processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great phone in budget. .. pubg performance was...</td>\n",
       "      <td>0</td>\n",
       "      <td>great phone budget pubg performance rough came...</td>\n",
       "      <td>[great, phone, budget, pubg, performance, roug...</td>\n",
       "      <td>0.900222</td>\n",
       "      <td>0.877657</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.910938</td>\n",
       "      <td>0.891804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Smartphone by Mi in this Range. . stop fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>good smartphone mi range stop r confused samsu...</td>\n",
       "      <td>[good, smartphone, mi, range, stop, r, confuse...</td>\n",
       "      <td>0.892999</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.926519</td>\n",
       "      <td>0.940637</td>\n",
       "      <td>0.853622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evil smooth phone. . and back camera quality i...</td>\n",
       "      <td>0</td>\n",
       "      <td>evil smooth phone back camera quality bad rear...</td>\n",
       "      <td>[evil, smooth, phone, back, camera, quality, b...</td>\n",
       "      <td>0.878147</td>\n",
       "      <td>0.911873</td>\n",
       "      <td>0.931737</td>\n",
       "      <td>0.928768</td>\n",
       "      <td>0.910587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thise is very nice mobile ...I like it very mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>thise nice mobile I like much delivery also fa...</td>\n",
       "      <td>[thise, nice, mobile, i, like, much, delivery,...</td>\n",
       "      <td>0.875378</td>\n",
       "      <td>0.843419</td>\n",
       "      <td>0.886922</td>\n",
       "      <td>0.954610</td>\n",
       "      <td>0.836108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I m meagerly fall short of üëç All section r sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>I meagerly fall short thumb section r superb d...</td>\n",
       "      <td>[i, meagerly, fall, short, thumb, section, r, ...</td>\n",
       "      <td>0.865953</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.951442</td>\n",
       "      <td>0.959166</td>\n",
       "      <td>0.888991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9348e003-ceb9-49b4-8e87-85d199e1649b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9348e003-ceb9-49b4-8e87-85d199e1649b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9348e003-ceb9-49b4-8e87-85d199e1649b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review  y  \\\n",
       "0  great phone in budget. .. pubg performance was...  0   \n",
       "1  Best Smartphone by Mi in this Range. . stop fo...  0   \n",
       "2  Evil smooth phone. . and back camera quality i...  0   \n",
       "3  Thise is very nice mobile ...I like it very mu...  1   \n",
       "4  I m meagerly fall short of üëç All section r sup...  0   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  great phone budget pubg performance rough came...   \n",
       "1  good smartphone mi range stop r confused samsu...   \n",
       "2  evil smooth phone back camera quality bad rear...   \n",
       "3  thise nice mobile I like much delivery also fa...   \n",
       "4  I meagerly fall short thumb section r superb d...   \n",
       "\n",
       "                                       clean_review2     phone    camera  \\\n",
       "0  [great, phone, budget, pubg, performance, roug...  0.900222  0.877657   \n",
       "1  [good, smartphone, mi, range, stop, r, confuse...  0.892999  0.831100   \n",
       "2  [evil, smooth, phone, back, camera, quality, b...  0.878147  0.911873   \n",
       "3  [thise, nice, mobile, i, like, much, delivery,...  0.875378  0.843419   \n",
       "4  [i, meagerly, fall, short, thumb, section, r, ...  0.865953  0.864542   \n",
       "\n",
       "    battery  delivery  processor  \n",
       "0  0.938197  0.910938   0.891804  \n",
       "1  0.926519  0.940637   0.853622  \n",
       "2  0.931737  0.928768   0.910587  \n",
       "3  0.886922  0.954610   0.836108  \n",
       "4  0.951442  0.959166   0.888991  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "xCOlVmhKN6Hz"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(df, \"clean_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbItOmG_N6Hz",
    "outputId": "f942327d-d584-4b41-a621-926c66c6be91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3294"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.source_vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsFwi5CQN6Hz"
   },
   "source": [
    "Saving the pytorch custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "dw53GmgPN6Hz"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset-new', 'wb') as dataset_file:\n",
    " \n",
    "  # Step 3\n",
    "    pickle.dump(dataset, dataset_file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# import pickle\n",
    " \n",
    "# # Step 2\n",
    "# with open('./dataset', 'rb') as config_dictionary_file:\n",
    " \n",
    "#     # Step 3\n",
    "#     config_dictionary = pickle.load(config_dictionary_file)\n",
    " \n",
    "#     # After config_dictionary is read from file\n",
    "#     print(config_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl5YHivpN6Hz"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 6.3 Word Embeddings </h2><a id = \"6.3\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "x6MulERmN6H0"
   },
   "outputs": [],
   "source": [
    "def get_emb_layer_with_weights(target_vocab, emb_model, trainable = False):\n",
    "\n",
    "    weights_matrix = np.zeros((len(target_vocab), config.EMB_DIM))\n",
    "    words_found = 0\n",
    "    \n",
    "    for i, word in enumerate(target_vocab):\n",
    "        weights_matrix[i] = np.concatenate([emb_model.wv[word]])\n",
    "        words_found += 1\n",
    "                \n",
    "    print(f\"Words found are : {words_found}\")\n",
    "    \n",
    "    weights_matrix = torch.tensor(weights_matrix, dtype = torch.float32).reshape(len(target_vocab), config.EMB_DIM)\n",
    "    emb_layer = nn.Embedding.from_pretrained(weights_matrix)\n",
    "    print(emb_layer)\n",
    "    if trainable:\n",
    "        emb_layer.weight.requires_grad = True\n",
    "    else:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "_NIgNg4TN6H0"
   },
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    def __init__(self, pad_idx, maxlen):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    \n",
    "    #__call__: a default method\n",
    "    ##   First the obj is created using MyCollate(pad_idx) in data loader\n",
    "    ##   Then if obj(batch) is called -> __call__ runs by default\n",
    "    def __call__(self, batch):\n",
    "        #get all source indexed sentences of the batch\n",
    "        source = [item[0] for item in batch] \n",
    "        #pad them using pad_sequence method from pytorch. \n",
    "#         source = pad_sequence(source, batch_first=False, padding_value = self.pad_idx)\n",
    "        \n",
    "        padded_sequence = torch.zeros((self.maxlen, len(batch)), dtype = torch.int)\n",
    "        \n",
    "        for idx, text in enumerate(source):\n",
    "            \n",
    "            if len(text) > self.maxlen:\n",
    "                padded_sequence[:, idx] = source[idx][: self.maxlen]\n",
    "            else:\n",
    "                padded_sequence[:len(source[idx]), idx] = padded_sequence[:len(source[idx]), idx] + source[idx]\n",
    "                \n",
    "        \n",
    "        #get all target indexed sentences of the batch\n",
    "        target = [item[1] for item in batch] \n",
    "        \n",
    "        target = torch.tensor(target, dtype = torch.float32).reshape(-1)\n",
    "        return padded_sequence, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VRYjTndN6H0"
   },
   "source": [
    "<h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 6.4 Initializing the Model </h2><a id = \"6.4\" ></a>\n",
    "\n",
    "![Ankit%20Architecture%20Updated.jpg](attachment:Ankit%20Architecture%20Updated.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "MAeS_XPDN6H0"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, embedding_layer):\n",
    "        super().__init__()\n",
    "#         self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional = True)\n",
    "        self.fc1 = nn.Linear(2*hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        max_len, N = text.shape\n",
    "        hidden = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        memory = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        hidden = hidden.to(config.DEVICE)\n",
    "        memory = memory.to(config.DEVICE)\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.lstm(embedded, (hidden, memory))\n",
    "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        y_pred = output[-1,:,:]\n",
    "        y_pred = self.fc1(y_pred)\n",
    "        y_pred = self.fc2(y_pred)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "                         \n",
    "        return y_pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqClrao-N6H0"
   },
   "source": [
    " <h2  style=\"text-align: center\" class=\"list-group-item list-group-item-success\"> 6.5 Training and K-fold Cross Validation </h2><a id = \"6.5\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "f5c8wPECN6H0"
   },
   "outputs": [],
   "source": [
    "def train_epochs(dataloader,model, loss_fn, optimizer):\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for review, label in tqdm(dataloader):\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*review.size(1)\n",
    "        prediction = (output > 0.5).float()\n",
    "        train_correct += (prediction == label).float().sum()\n",
    "        \n",
    "    return train_loss, train_correct\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ANZ3zvwTN6H0"
   },
   "outputs": [],
   "source": [
    "def val_epochs(dataloader, model, loss_fn):\n",
    "    val_correct = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "#     hidden = model.init_hidden(config.BATCH_SIZE)\n",
    "\n",
    "    for review, label in dataloader:\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        \n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        val_loss += loss.item()*review.size(1)\n",
    "        prediction = (output > 0.5).float()\n",
    "        val_correct += (prediction == label).float().sum()\n",
    "#         prediction = \n",
    "    return val_loss, val_correct\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1PRSLZ4N6H0",
    "outputId": "b0614f7f-d39e-4506-c451-b5b569a8e41b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found are : 3294\n",
      "Embedding(3294, 100)\n",
      "-----------------------------------------------------------0-fold of the model-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6925234516606488 |  Val Loss : 0.6902687032934778 | Train Acc : 51.756893157958984 | Val Acc : 61.862640380859375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.687898789328377 |  Val Loss : 0.6822971335682984 | Train Acc : 55.999481201171875 | Val Acc : 56.65972900390625 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6471030033857236 |  Val Loss : 0.4290990746356198 | Train Acc : 66.21551513671875 | Val Acc : 88.34547424316406 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.40185272217161455 |  Val Loss : 0.46891588499841286 | Train Acc : 83.30297088623047 | Val Acc : 82.62226867675781 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.2815311117478797 |  Val Loss : 0.5079976782342274 | Train Acc : 89.12025451660156 | Val Acc : 80.02081298828125 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.23510784982766167 |  Val Loss : 0.17139729837287104 | Train Acc : 90.95523071289062 | Val Acc : 92.97606658935547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:11<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.2149717786360507 |  Val Loss : 0.6950439439231721 | Train Acc : 91.6059341430664 | Val Acc : 75.85848236083984 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19143784575974923 |  Val Loss : 0.1323323956168374 | Train Acc : 92.80323028564453 | Val Acc : 95.26535034179688 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19531366870559672 |  Val Loss : 0.14132610605360937 | Train Acc : 92.16554260253906 | Val Acc : 94.95317077636719 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1811191682266978 |  Val Loss : 1.1036894823832517 | Train Acc : 92.84226989746094 | Val Acc : 59.8335075378418 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.18636255607373511 |  Val Loss : 0.1534952915760104 | Train Acc : 92.62102508544922 | Val Acc : 94.48491668701172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17333641346061154 |  Val Loss : 0.12738280688799167 | Train Acc : 93.15460968017578 | Val Acc : 95.10926055908203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17458046706687158 |  Val Loss : 2.218032292009435 | Train Acc : 92.89432525634766 | Val Acc : 50.57231903076172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17907286125474273 |  Val Loss : 0.2131193258007843 | Train Acc : 93.31077575683594 | Val Acc : 90.99896240234375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.16099324136951096 |  Val Loss : 0.13155815545634272 | Train Acc : 93.51900482177734 | Val Acc : 95.42143249511719 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.16095800179831066 |  Val Loss : 0.4192333305167358 | Train Acc : 93.64913940429688 | Val Acc : 79.81269073486328 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1633179959322809 |  Val Loss : 0.15732922856371295 | Train Acc : 93.29776000976562 | Val Acc : 93.96461486816406 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1628284579669433 |  Val Loss : 0.12253703284450457 | Train Acc : 93.84435272216797 | Val Acc : 95.16128540039062 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15462358571144905 |  Val Loss : 0.15716953682456394 | Train Acc : 93.77928161621094 | Val Acc : 95.21331787109375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15256120382630223 |  Val Loss : 0.12148967479877988 | Train Acc : 93.77928161621094 | Val Acc : 95.10926055908203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15246872434015388 |  Val Loss : 0.12706348405614046 | Train Acc : 94.1827163696289 | Val Acc : 95.0572280883789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15261406111320067 |  Val Loss : 0.12786890252742386 | Train Acc : 93.68818664550781 | Val Acc : 94.84911346435547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14844726722635124 |  Val Loss : 0.1177999878905008 | Train Acc : 94.07860565185547 | Val Acc : 95.31737518310547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1468098203242911 |  Val Loss : 0.1401654442580384 | Train Acc : 94.36491394042969 | Val Acc : 94.48491668701172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1448473091892227 |  Val Loss : 0.11595569881266535 | Train Acc : 94.19573211669922 | Val Acc : 95.73361206054688 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14225017101848608 |  Val Loss : 0.12108871116400788 | Train Acc : 94.49504852294922 | Val Acc : 95.57752990722656 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14447962884819798 |  Val Loss : 0.11643070506518774 | Train Acc : 94.36491394042969 | Val Acc : 95.52549743652344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14172446917992654 |  Val Loss : 0.1128507752076148 | Train Acc : 94.28682708740234 | Val Acc : 95.68158721923828 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14012701970884817 |  Val Loss : 0.11443033386273824 | Train Acc : 94.54711151123047 | Val Acc : 95.73361206054688 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1391936823718913 |  Val Loss : 0.12075159212554495 | Train Acc : 94.40396118164062 | Val Acc : 95.8376693725586 |\n",
      "Words found are : 3294\n",
      "Embedding(3294, 100)\n",
      "-----------------------------------------------------------1-fold of the model-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6919862624803145 |  Val Loss : 0.6899813696904954 | Train Acc : 52.47885513305664 | Val Acc : 56.064552307128906 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6860796689366705 |  Val Loss : 0.6798753391200835 | Train Acc : 58.68574905395508 | Val Acc : 59.396148681640625 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6057751744762596 |  Val Loss : 0.261071651320728 | Train Acc : 69.368896484375 | Val Acc : 90.68193054199219 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.3488361291010502 |  Val Loss : 0.6311187797091719 | Train Acc : 86.12882232666016 | Val Acc : 76.15824890136719 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.2476939295939059 |  Val Loss : 0.3549976396349679 | Train Acc : 90.48796081542969 | Val Acc : 84.90369415283203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.22071378943240713 |  Val Loss : 1.3247804479441523 | Train Acc : 91.3988265991211 | Val Acc : 64.18531799316406 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.20755514719304746 |  Val Loss : 0.741973501150649 | Train Acc : 92.17957305908203 | Val Acc : 71.10880279541016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19055128455084488 |  Val Loss : 0.5823635314821515 | Train Acc : 92.55693054199219 | Val Acc : 79.69807434082031 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1773333206437116 |  Val Loss : 0.17726322173898218 | Train Acc : 93.05139923095703 | Val Acc : 93.18063354492188 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.165247009766319 |  Val Loss : 0.24650158396234104 | Train Acc : 93.68900299072266 | Val Acc : 91.98334503173828 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:13<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.16141653983776805 |  Val Loss : 0.1641867196205315 | Train Acc : 93.68900299072266 | Val Acc : 93.54502868652344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15731414679532402 |  Val Loss : 0.16811828580740712 | Train Acc : 93.71502685546875 | Val Acc : 93.49297332763672 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:11<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1661083155752159 |  Val Loss : 0.1663960289195052 | Train Acc : 93.48080444335938 | Val Acc : 94.01353454589844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15733825013710448 |  Val Loss : 0.19819715785862319 | Train Acc : 93.78009033203125 | Val Acc : 92.19156646728516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15428191232813127 |  Val Loss : 0.16678043346917998 | Train Acc : 93.92322540283203 | Val Acc : 94.27381896972656 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14564405557934 |  Val Loss : 2.8807749174464248 | Train Acc : 94.24853515625 | Val Acc : 50.91098403930664 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1755283970860843 |  Val Loss : 0.1667801851071204 | Train Acc : 93.41574096679688 | Val Acc : 93.33679962158203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:08<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14440069989772075 |  Val Loss : 0.16271670148812162 | Train Acc : 94.43070983886719 | Val Acc : 93.80530548095703 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14075894864589927 |  Val Loss : 0.1949589929578827 | Train Acc : 94.26155090332031 | Val Acc : 91.67100524902344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1436473292823961 |  Val Loss : 0.21555282805989584 | Train Acc : 94.30058288574219 | Val Acc : 92.92034912109375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1400454233359926 |  Val Loss : 0.1577026004465355 | Train Acc : 94.45673370361328 | Val Acc : 94.53409576416016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1401934679852109 |  Val Loss : 0.19142171390476928 | Train Acc : 94.45673370361328 | Val Acc : 92.34773254394531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:11<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14031122885668673 |  Val Loss : 0.21842734894207652 | Train Acc : 94.46974182128906 | Val Acc : 90.4216537475586 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14153928745516184 |  Val Loss : 0.17523036164462855 | Train Acc : 94.46974182128906 | Val Acc : 93.28475189208984 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13370721319238318 |  Val Loss : 0.18227517465081014 | Train Acc : 94.78204345703125 | Val Acc : 93.02446746826172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13534900291847693 |  Val Loss : 0.19518352550564005 | Train Acc : 94.53480529785156 | Val Acc : 93.07652282714844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13351546171167955 |  Val Loss : 0.16889688791149626 | Train Acc : 94.88613891601562 | Val Acc : 93.44091796875 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1363088148306127 |  Val Loss : 0.16665882449296537 | Train Acc : 94.72999572753906 | Val Acc : 93.28475189208984 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13244194486308733 |  Val Loss : 0.6101440197377543 | Train Acc : 94.91216278076172 | Val Acc : 81.10359191894531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13326119272815148 |  Val Loss : 0.14738663261342272 | Train Acc : 94.79505157470703 | Val Acc : 94.42998504638672 |\n",
      "Words found are : 3294\n",
      "Embedding(3294, 100)\n",
      "-----------------------------------------------------------2-fold of the model-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6921368829678155 |  Val Loss : 0.6898274641990165 | Train Acc : 52.01041030883789 | Val Acc : 52.5767822265625 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6872368522875482 |  Val Loss : 0.6811195237136396 | Train Acc : 57.970069885253906 | Val Acc : 62.727745056152344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6164654172777587 |  Val Loss : 0.5677465369060969 | Train Acc : 69.68119812011719 | Val Acc : 67.36074829101562 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.3730944041024576 |  Val Loss : 0.2415656797560722 | Train Acc : 84.60637664794922 | Val Acc : 90.83810424804688 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.2525314716487716 |  Val Loss : 0.6238091782449062 | Train Acc : 89.87638092041016 | Val Acc : 73.29515838623047 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.21909901961034664 |  Val Loss : 0.324390615536824 | Train Acc : 91.45087432861328 | Val Acc : 86.10099029541016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.20211684111367595 |  Val Loss : 0.20766628545625082 | Train Acc : 92.38776397705078 | Val Acc : 91.56688690185547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19715974168802286 |  Val Loss : 0.15446056685042467 | Train Acc : 92.07546997070312 | Val Acc : 94.32586669921875 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17938563240838656 |  Val Loss : 0.16798846563154649 | Train Acc : 92.89524841308594 | Val Acc : 92.972412109375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17845919565015902 |  Val Loss : 0.6329462215464847 | Train Acc : 92.84320068359375 | Val Acc : 78.7090072631836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17097675577751328 |  Val Loss : 0.15719025279843732 | Train Acc : 93.12947082519531 | Val Acc : 93.59708404541016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1621877266512184 |  Val Loss : 0.20912166657328668 | Train Acc : 93.63695526123047 | Val Acc : 90.31754302978516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15759438934385117 |  Val Loss : 0.1850106351752414 | Train Acc : 93.75406646728516 | Val Acc : 91.3586654663086 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15566363458266566 |  Val Loss : 0.14680147635372803 | Train Acc : 93.88418579101562 | Val Acc : 94.06558990478516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1505898785110255 |  Val Loss : 0.21090901812527837 | Train Acc : 94.2225112915039 | Val Acc : 90.31754302978516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14277981234473228 |  Val Loss : 0.15494342824894564 | Train Acc : 94.44371795654297 | Val Acc : 93.909423828125 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1453540191167048 |  Val Loss : 0.1455853618817178 | Train Acc : 94.41769409179688 | Val Acc : 94.42998504638672 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14086664490784695 |  Val Loss : 0.15386337122527466 | Train Acc : 94.58685302734375 | Val Acc : 93.909423828125 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14206999174028964 |  Val Loss : 0.14883544453105102 | Train Acc : 94.52179718017578 | Val Acc : 94.53409576416016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14194996105670618 |  Val Loss : 0.18025315422875024 | Train Acc : 94.50878143310547 | Val Acc : 91.93128204345703 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1378366121376344 |  Val Loss : 0.13728603508026727 | Train Acc : 94.62589263916016 | Val Acc : 94.89849090576172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13829431986277493 |  Val Loss : 0.14768137491058717 | Train Acc : 94.35263061523438 | Val Acc : 94.22175598144531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13412189727640608 |  Val Loss : 0.1541259313009016 | Train Acc : 94.75601959228516 | Val Acc : 94.16970825195312 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13440630420043861 |  Val Loss : 0.1352517013915282 | Train Acc : 94.5998764038086 | Val Acc : 94.89849090576172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1336025505939289 |  Val Loss : 0.13965958130280723 | Train Acc : 94.69095611572266 | Val Acc : 95.00260162353516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1312145186327616 |  Val Loss : 0.15913142388885795 | Train Acc : 94.86011505126953 | Val Acc : 93.7011947631836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13388000892095933 |  Val Loss : 0.13922167909954603 | Train Acc : 94.74300384521484 | Val Acc : 94.53409576416016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13385753132543474 |  Val Loss : 0.14391493570022693 | Train Acc : 94.70396423339844 | Val Acc : 94.63821411132812 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13008779291216244 |  Val Loss : 0.3076498461436366 | Train Acc : 94.95121002197266 | Val Acc : 85.58042907714844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13189428948258608 |  Val Loss : 0.17931704025522635 | Train Acc : 94.83409881591797 | Val Acc : 92.66007232666016 |\n",
      "Words found are : 3294\n",
      "Embedding(3294, 100)\n",
      "-----------------------------------------------------------3-fold of the model-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6917208979714592 |  Val Loss : 0.6884753907303957 | Train Acc : 52.4398193359375 | Val Acc : 62.93597412109375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6838805405521207 |  Val Loss : 0.6761425742564383 | Train Acc : 58.763824462890625 | Val Acc : 53.61790466308594 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.5682911051971694 |  Val Loss : 0.728275312014789 | Train Acc : 73.03839111328125 | Val Acc : 68.29776000976562 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.31477803820253347 |  Val Loss : 0.7885054186692404 | Train Acc : 87.50813293457031 | Val Acc : 68.08953857421875 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.24988846192615097 |  Val Loss : 0.2267664666929976 | Train Acc : 90.48796081542969 | Val Acc : 91.87923431396484 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.22013604493209427 |  Val Loss : 0.4757742447345161 | Train Acc : 91.5940170288086 | Val Acc : 79.3857421875 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19330690915350335 |  Val Loss : 0.5440109239029177 | Train Acc : 92.58295440673828 | Val Acc : 71.73347473144531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.19184556706973926 |  Val Loss : 0.8879641439069502 | Train Acc : 92.58295440673828 | Val Acc : 62.675689697265625 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17971999691768986 |  Val Loss : 0.7419970543374672 | Train Acc : 92.58295440673828 | Val Acc : 68.55804443359375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1685303157608697 |  Val Loss : 0.1765954292455435 | Train Acc : 93.376708984375 | Val Acc : 93.44091796875 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1652574959092894 |  Val Loss : 0.4707547318401714 | Train Acc : 93.63695526123047 | Val Acc : 81.36387634277344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1661538787801776 |  Val Loss : 0.2653387044631585 | Train Acc : 93.41574096679688 | Val Acc : 88.23529815673828 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15457258469079152 |  Val Loss : 0.1678292153559272 | Train Acc : 93.74105072021484 | Val Acc : 93.33679962158203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15271804588001583 |  Val Loss : 0.15967851222523297 | Train Acc : 94.1834716796875 | Val Acc : 94.06558990478516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14565796980473153 |  Val Loss : 0.5887506557589728 | Train Acc : 94.2875747680664 | Val Acc : 71.31702423095703 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14609412582834763 |  Val Loss : 0.1549780133525991 | Train Acc : 94.39167022705078 | Val Acc : 93.75325775146484 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14486269853529252 |  Val Loss : 0.3180422091192165 | Train Acc : 94.2875747680664 | Val Acc : 84.59136199951172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1421955396699378 |  Val Loss : 0.8549506534724838 | Train Acc : 94.58685302734375 | Val Acc : 63.820926666259766 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14706650703234106 |  Val Loss : 0.17201997306564398 | Train Acc : 94.2745590209961 | Val Acc : 94.01353454589844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.137688120879674 |  Val Loss : 0.20060101036711528 | Train Acc : 94.76902770996094 | Val Acc : 92.13951110839844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13723502443568925 |  Val Loss : 0.16161557466261 | Train Acc : 94.74300384521484 | Val Acc : 93.59708404541016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13520828930275708 |  Val Loss : 0.15390904888341989 | Train Acc : 94.63890838623047 | Val Acc : 94.42998504638672 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13667843039538385 |  Val Loss : 0.2209689365224772 | Train Acc : 94.78204345703125 | Val Acc : 92.13951110839844 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13285493585817326 |  Val Loss : 0.15213110599664895 | Train Acc : 94.82107543945312 | Val Acc : 93.75325775146484 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13473583971796751 |  Val Loss : 0.2045012224079699 | Train Acc : 94.62589263916016 | Val Acc : 91.67100524902344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13183611188139632 |  Val Loss : 0.7943829732100086 | Train Acc : 94.88613891601562 | Val Acc : 72.2540283203125 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13857156729729206 |  Val Loss : 0.1477127418829587 | Train Acc : 94.69095611572266 | Val Acc : 94.11764526367188 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13049307364762003 |  Val Loss : 0.14607708056722532 | Train Acc : 95.04228973388672 | Val Acc : 94.22175598144531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.12718404117309978 |  Val Loss : 0.4884495646040741 | Train Acc : 95.06832122802734 | Val Acc : 73.19104766845703 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13040017233791876 |  Val Loss : 0.16040952975087486 | Train Acc : 95.120361328125 | Val Acc : 94.22175598144531 |\n",
      "Words found are : 3294\n",
      "Embedding(3294, 100)\n",
      "-----------------------------------------------------------4-fold of the model-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6921812598241485 |  Val Loss : 0.6905374341430545 | Train Acc : 52.179569244384766 | Val Acc : 56.01249313354492 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6868907425724692 |  Val Loss : 0.6829576943145327 | Train Acc : 57.033180236816406 | Val Acc : 60.90577697753906 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6188574043472789 |  Val Loss : 1.3460810607699663 | Train Acc : 67.00064849853516 | Val Acc : 50.65070343017578 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.37431193155441955 |  Val Loss : 1.4662436589517207 | Train Acc : 84.54131317138672 | Val Acc : 53.774078369140625 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.264089649413496 |  Val Loss : 0.17927929487531227 | Train Acc : 90.30579376220703 | Val Acc : 93.28475189208984 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.23079359843968258 |  Val Loss : 0.2095335648510991 | Train Acc : 91.3337631225586 | Val Acc : 92.60801696777344 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.20480599974996483 |  Val Loss : 0.6535062678812779 | Train Acc : 92.32270812988281 | Val Acc : 75.63768768310547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.20457263326801955 |  Val Loss : 0.16005051106540316 | Train Acc : 91.98438262939453 | Val Acc : 93.75325775146484 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1912915678397936 |  Val Loss : 0.16487920227645275 | Train Acc : 92.56993865966797 | Val Acc : 93.28475189208984 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17390104185307498 |  Val Loss : 0.17731644003761118 | Train Acc : 93.42875671386719 | Val Acc : 92.66007232666016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.17228164572799523 |  Val Loss : 0.49456193653759023 | Train Acc : 93.42875671386719 | Val Acc : 77.51171112060547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1667274415027653 |  Val Loss : 0.39943167210625896 | Train Acc : 93.51984405517578 | Val Acc : 88.755859375 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.16303547784618225 |  Val Loss : 0.4243072021803744 | Train Acc : 93.67599487304688 | Val Acc : 85.94481658935547 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.16567656894201727 |  Val Loss : 0.5053610571958018 | Train Acc : 93.53285217285156 | Val Acc : 81.41592407226562 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15656591245181078 |  Val Loss : 0.17549823069598822 | Train Acc : 93.79310607910156 | Val Acc : 93.7011947631836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1561648694426306 |  Val Loss : 0.14809648001994133 | Train Acc : 94.05335235595703 | Val Acc : 93.33679962158203 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15073734122869561 |  Val Loss : 0.15396598905139738 | Train Acc : 94.118408203125 | Val Acc : 93.909423828125 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15025878250986707 |  Val Loss : 0.3726900486922292 | Train Acc : 94.00129699707031 | Val Acc : 85.78865051269531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.15075977179176364 |  Val Loss : 0.14242438418705372 | Train Acc : 94.23551940917969 | Val Acc : 94.58615112304688 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14507123998953447 |  Val Loss : 1.3378344862598233 | Train Acc : 94.378662109375 | Val Acc : 65.38261413574219 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14315723734547275 |  Val Loss : 0.7603951081284989 | Train Acc : 94.72999572753906 | Val Acc : 75.2732925415039 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.147414909259561 |  Val Loss : 0.14872348048983122 | Train Acc : 94.41769409179688 | Val Acc : 93.7011947631836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.14104136080422336 |  Val Loss : 0.284118216567203 | Train Acc : 94.48275756835938 | Val Acc : 90.68193054199219 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13975391704649723 |  Val Loss : 0.17001876402559038 | Train Acc : 94.56082916259766 | Val Acc : 93.7011947631836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13624696176906317 |  Val Loss : 0.13960815898643564 | Train Acc : 94.74300384521484 | Val Acc : 94.53409576416016 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13551278591650448 |  Val Loss : 0.14893754217618535 | Train Acc : 94.75601959228516 | Val Acc : 94.42998504638672 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13900439550757177 |  Val Loss : 0.23193671714508676 | Train Acc : 94.54782104492188 | Val Acc : 89.74492645263672 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:10<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.13560432053317129 |  Val Loss : 0.13903035792666182 | Train Acc : 94.80806732177734 | Val Acc : 94.06558990478516 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 25.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1373941200541147 |  Val Loss : 0.34376297198441547 | Train Acc : 94.87313079833984 | Val Acc : 82.71733856201172 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 241/241 [00:09<00:00, 26.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.1322991198081482 |  Val Loss : 0.1566541912027109 | Train Acc : 94.76902770996094 | Val Acc : 93.80530548095703 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# sfk = StratifiedKFold(n_splits = config.FOLDS)\n",
    "kfold = KFold(n_splits = config.FOLDS)\n",
    "model_state_dicts = {}\n",
    " \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(np.arange(len(dataset)))):\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size = config.BATCH_SIZE, sampler = train_sampler, collate_fn = MyCollate(0, config.MAX_LEN))\n",
    "    val_loader = DataLoader(dataset, batch_size = config.BATCH_SIZE, sampler = val_sampler, collate_fn = MyCollate(0, config.MAX_LEN))  \n",
    "    \n",
    "    VOCAB_SIZE = len(dataset.source_vocab)\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = 1\n",
    "    VOCAB = list(dataset.source_vocab.stoi)\n",
    "\n",
    "    embedding_layer = get_emb_layer_with_weights(target_vocab = VOCAB, emb_model = fasttext_model, trainable = False)\n",
    "\n",
    "    model = Model(VOCAB_SIZE, config.EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, embedding_layer)\n",
    "    model = model.to(config.DEVICE)\n",
    "    \n",
    "#     model\n",
    "#     model = Model(2, len(dataset.source_vocab), 128, 100, 1 ).to(config.DEVICE)\n",
    "#     hidden = model.init_hidden(config.BATCH_SIZE)\n",
    "#     model.hidden = hidden\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    print(f\"-----------------------------------------------------------{fold}-fold of the model-----------------------------------------------------------\")\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_loss, train_correct = train_epochs(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_correct = val_epochs(val_loader, model, loss_fn)  \n",
    "        \n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        val_loss = val_loss/len(val_loader.sampler)\n",
    "        train_acc = (train_correct/len(train_loader.sampler))*100\n",
    "        val_acc = (val_correct/len(val_loader.sampler))*100\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc.cpu().numpy().tolist())\n",
    "        val_accs.append(val_acc.cpu().numpy().tolist())\n",
    "        \n",
    "        print(f\"| Train Loss : {train_loss} |\", end = \" \")\n",
    "        print(f\" Val Loss : {val_loss} |\", end = \" \")\n",
    "        print(f\"Train Acc : {train_acc} |\", end = \" \")\n",
    "        print(f\"Val Acc : {val_acc} |\")\n",
    "\n",
    "        \n",
    "    # Saving the state dicts for the model\n",
    "    model_state_dicts.update({f\"LSTM-Model-for-{fold}\" : model.state_dict(),\n",
    "                             f\"Model-Optimizer-for-{fold}\" : optimizer.state_dict()})\n",
    "    \n",
    "#     # summarize history for accuracy\n",
    "#     plt.plot(train_accs)\n",
    "#     plt.plot(val_accs)\n",
    "#     plt.title('Model Accuracy')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     # summarize history for loss\n",
    "#     plt.plot(train_losses)\n",
    "#     plt.plot(val_losses)\n",
    "#     plt.title('Model Loss')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "pwoMwR8bN6H0"
   },
   "outputs": [],
   "source": [
    "torch.save(model_state_dicts, \"My-Model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGfB6I45N6H0"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">7. Inference</h1><a id = \"7\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "aW3DiTnUN6H0"
   },
   "outputs": [],
   "source": [
    "def numericalize(text):\n",
    "    \n",
    "    numerialized_source = [] \n",
    "    numerialized_source = [dataset.source_vocab.stoi[\"<SOS>\"]]\n",
    "    numerialized_source += dataset.source_vocab.numericalize(text)\n",
    "    numerialized_source.append(dataset.source_vocab.stoi[\"<EOS>\"])\n",
    "    \n",
    "    return numerialized_source\n",
    "\n",
    "def padding(source):\n",
    "    padded_sequence = torch.zeros(config.MAX_LEN, 1, dtype = torch.int)\n",
    "    source = torch.tensor(source)\n",
    "    \n",
    "    if len(source) > config.MAX_LEN:\n",
    "        padded_sequence[:, 0] = source[: config.MAX_LEN]\n",
    "    else:\n",
    "        padded_sequence[:len(source), 0] = padded_sequence[:len(source), 0] + source\n",
    "    \n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Ac1EUsscN6H0"
   },
   "outputs": [],
   "source": [
    "def infer_processing(text):\n",
    "    \n",
    "    text = preprocessing(text)\n",
    "    text = numericalize(text)\n",
    "    text = padding(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "HmJCVB9KN6H0"
   },
   "outputs": [],
   "source": [
    "aspects = [\"phone\", \"camera\", \"battery\", \"neutral\", \"processor\"]\n",
    "\n",
    "def get_similarity(text, aspect):\n",
    "    try:\n",
    "#         text = \" \".join(text)\n",
    "        return fasttext_model.wv.n_similarity(text, aspect)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def best_aspect(text, aspects):\n",
    "    a = []\n",
    "    \n",
    "    for aspect in aspects:\n",
    "        a.append(get_similarity(text, aspect))\n",
    "    \n",
    "    return aspects[np.argmax(a)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "_SuUSRdAN6H0"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample = \"I am really impressed with the phone's great battery backup.\"\n",
    "\n",
    "ba = best_aspect(preprocessing(sample), aspects)\n",
    "\n",
    "a = infer_processing(sample).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "5C-mkEjUN6H0"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentiment = model(a)\n",
    "sentiment = sentiment.cpu().detach().numpy()[0]\n",
    "\n",
    "if sentiment > 0.5:\n",
    "    sentiment = 'Positively'\n",
    "else :\n",
    "    sentiment = 'Negatively'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtel2sQiN6H0",
    "outputId": "9e890cbc-135c-4f5e-a2e1-47ad1f78b559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviewer is talking Positively about the battery of the phone in his/her comment\n"
     ]
    }
   ],
   "source": [
    "print(f\"The reviewer is talking {sentiment} about the {ba} of the phone in his/her comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "pX4AOKGcN6H1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "tShbJ2MjN6H1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTRUaZB0N6H1"
   },
   "source": [
    "<h1  style=\"text-align: center\" class=\"list-group-item list-group-item-action active\">8. References</h1><a id = \"8\" ></a>\n",
    "\n",
    "\n",
    "- [A Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n",
    "- [Python SQLite](https://www.geeksforgeeks.org/python-sqlite/)\n",
    "- [What on Earth is Unicode Normalization?](https://towardsdatascience.comwhat-on-earth-is-unicode-normalization-56c005c55ad0)\n",
    "- [How to handle Emoji ‚ÄòüòÑ‚Äô & Emoticon ‚Äò :-) ‚Äô in text preprocessing?](https://medium.com/geekculture/text-preprocessing-how-to-handle-emoji-emoticon-641bbfa6e9e7)\n",
    "- [Spelling checker in Python](https://www.geeksforgeeks.org/spelling-checker-in-python/)\n",
    "- [NLPAUG ‚Äì A Python library to Augment Your Text Data](https://www.analyticsvidhya.com/blog/2021/08/nlpaug-a-python-library-to-augment-your-text-data/)\n",
    "- [Topic Modeling in Python: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "8Sr0hcmTN6H1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "gdKwLazoN6H1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "aspect-based-sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
